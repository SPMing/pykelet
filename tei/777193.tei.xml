<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="file:///home/joseph/Desktop/grobid/grobid-home/schemas/rng/Grobid.rng" schematypens="http://relaxng.org/ns/structure/1.0"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Maximum Patch Method for Directional Dark Matter Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2008-07-22">22 Jul 2008 (Dated: July 22, 2008)</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">Shawn</forename>
								<surname>Henderson</surname>
							</persName>
							<affiliation>
								<orgName type="department" key="dep1">Department of Physics</orgName>
								<orgName type="department" key="dep2">Laboratory for Nuclear Science</orgName>
								<orgName type="institution" key="instit1">Massachusetts Institute of Technology</orgName>
								<orgName type="institution" key="instit2">MIT Kavli Institute for Astrophysics and Space Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Jocelyn</forename>
								<surname>Monroe</surname>
							</persName>
							<affiliation>
								<orgName type="department" key="dep1">Department of Physics</orgName>
								<orgName type="department" key="dep2">Laboratory for Nuclear Science</orgName>
								<orgName type="institution" key="instit1">Massachusetts Institute of Technology</orgName>
								<orgName type="institution" key="instit2">MIT Kavli Institute for Astrophysics and Space Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">Peter</forename>
								<surname>Fisher</surname>
							</persName>
							<affiliation>
								<orgName type="department">Department of Physics</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The Maximum Patch Method for Directional Dark Matter Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2008-07-22">22 Jul 2008 (Dated: July 22, 2008)</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords scheme="pacs">
					<term>0620Dk</term>
					<term>1480-j</term>
					<term>1480Ly</term>
					<term>9535+d</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Present and planned dark matter detection experiments search for WIMP-induced nuclear recoils in poorly known background conditions. In this environment, the maximum gap statistical method provides a way of setting more sensitive cross section upper limits by incorporating known signal information. We give a recipe for the numerical calculation of upper limits for planned directional dark matter detection experiments, that will measure both recoil energy and angle, based on the gaps between events in two-dimensional phase space.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
			<div>
				<head>I. INTRODUCTION</head>

				<p>Dark matter comprises approximately 25% of the mass of the universe [1]. The generic dark matter candidate is a weakly interacting massive particle (WIMP). If WIMPs are supersymmetric particles, the predicted mass is in the range of 10 to 10 4 GeV/c 2 , and the expected cross section lies in the range of 10 −42 to 10 −48 cm 2 [2]. Many experiments seek to detect dark matter particles via their elastic scattering interactions with detector nuclei [3]. Recent measurements [4, 5] limit the cross section to be less than approximately 5 × 10 −44 cm 2 . Given the small size of the expected WIMP cross section, discrimination against backgrounds is of paramount importance in direct detection experiments. For the same reason, there is much to gain by optimizing the statistical methods used to interpret experimental data as upper limits on the WIMP interaction cross section [6].</p>

				<p>In this paper, we develop a new statistic, the maximum patch, for setting limits on the WIMP-nucleus interaction cross section. This method is motivated by directional dark matter experiments, which seek to measure both the nuclear recoil energy, and the recoil angle of the struck nucleon in WIMP-nucleon interactions. In section II we introduce the theoretical distributions used for setting limits, and in sections III and IV we discuss limit setting techniques within the context of one-and twodimensional WIMP detection experiments. In section V we compare results in the cases of (i) observing a signal with no background, (ii) observing some signal and some background, and (iii) observing only background. * Electronic address: shawnh@mit.edu</p>

			</div>
			<div>
				<head>II. SETTING DARK MATTER CROSS SECTION LIMITS</head>

				<p>Direct detection experiments typically measure the energy deposited by the recoil nucleus [3], infer the true nuclear recoil energy, and set upper limits on the WIMPnucleus interaction cross section by comparing the theoretical distribution with this one-dimensional data set. The theoretical event rate distribution is given by [7]</p>

				<figure>
					<trash>dN dE = R 0 E 0 r 1 2πv 2 0 vmax v threshold 1 v f (v, v E )d 3 v (1) where E is the nuclear recoil energy, E 0 = 1 2 m D v 2 0</trash>


				</figure>

				<p>is the dark matter particle&apos;s kinetic energy, r = 4m D m T /(m D + m T ) 2 with dark matter particle mass m D and target nucleus mass m T , v threshold and v max are the minimum observable and escape velocities of the dark matter (taken to be the dark matter velocity that produces a maximum recoil energy equal to the experimental lower limit recoil energy threshold and ∞ here respectively, for simplicity), v E = 244 km/s is the Earth&apos;s velocity relative to the dark matter halo, and f (v, v E ) is the dark matter velocity distribution function, assumed here to be a Maxwell-Boltzmann distribution with RMS velocity v 0 = 230 km/s. The normalization factor R 0 is the event rate per unit mass with (v threshold , v max )</p>

				<figure>
					<trash>= (0,∞), R 0 = 2 √ π N 0 A ρ D m D v 0 σ 0 (2)</trash>


				</figure>

				<p>where N 0 is Avogadro&apos;s number, A is the atomic mass of the target, ρ D is the dark matter density, taken here to be 0.3 (GeV /c 2 )/cm 3 , and σ 0 is the zero momentum-transfer dark matter-nucleus interaction cross section. We use the fact that the differential interaction rate scales simply with σ 0 in the following discussion of limit setting techniques. A new thrust in the field of WIMP searches has been to develop detector sensitivity in a second dimension, the nuclear recoil angle [8, 9, 10]. The WIMP-nucleus interaction signal is expected to be highly anisotropic in recoil direction because of the earth&apos;s motion with respect to the WIMP halo [11]. In contrast, the backgrounds of most WIMP experiments are relatively isotropic in recoil angle in the detector coordinate system [12], and therefore this experimental approach can provide increased discrimination against backgrounds. It has recently been suggested that WIMP direct detection searches relying on a recoil energy signature alone may be insufficient for distinguishing WIMP events from nuclear recoils if the WIMP-nucleus cross section is smaller than the coherent scattering cross section for solar neutrinos [13]. This makes directional detection particularly attractive, since solar neutrino-induced recoils point back to the sun, unlike recoils from WIMP interactions. Directional detection could also potentially probe the velocity distribution of our galaxy&apos;s dark matter halo [14]. The theoretical distribution as a function of nuclear recoil energy E and recoil angle ψ (where ψ is the angle in the detector lab frame between the nuclear recoil track observed in the detector and the direction the dark matter &quot; wind &quot; is blowing , which is normally taken to be the vector pointing from the constellation Cygnus to Earth) is given by [7, 11]</p>

				<figure>
					<trash>d 2 N (v E , ∞) dEd(cosψ) = 1 2 R 0 E 0 r exp − (v E cosψ − v min ) 2 v 2 0 (3) where v min = (E/E 0 r) 1/2 v 0 is the smallest dark matter particle velocity which can produce a nuclear recoil with energy E. Given a theoretical distribution, one can compare with an observation to set a limit on the WIMP-nucleus interaction cross section. The usual method to obtain an upper limit at some confidence</trash>


				</figure>

				<p>level is to vary the theoretical parameters until the appropriate cumulative probability distribution function (CDF) takes on the confidence level desired (0.9 for a 90% confidence level upper limit) when evaluated at the observed statistic (e.g. the number of observed events). In the following two sections, we discuss upper limit calculations using the one-and two-dimensional theoretical distributions respectively , together with several statistics of interest.</p>

			</div>
			<div>
				<head>III. DARK MATTER STATISTICS IN ONE DIMENSION</head>

				<p>Here we compare the traditional Poisson method with the maximum gap, a statistic often used in dark matter experiments for obtaining an upper limit with onedimensional data [4, 5]. While the traditional Poisson method is based solely on the number of counts observed [15], the maximum gap procedure incorporates what is known about the shape of the expected signal into the limit determination [6]. For the discussion that follows, consider a series of nuclear recoil energy measurements {E 1 , ..., E N } where N is the total number of measurements. Assume the data points are distributed with a known theoretical function dN ( λ)/dE, where the λ are the parameters of the theoretical model dN/dE given in equation 1. Assuming standard values for the dark matter halo parameters, there is only one free parameter which we then vary to set upper limits, the zero-momentum transfer dark matter-nucleus interaction cross section σ 0 in equation 2.</p>

			</div>
			<div>
				<head>A. Poisson Method</head>

				<p>A straightforward cross section upper limit on a given data set can be obtained by employing the Poisson method. To set a limit, we are interested in the probability , given a value of the cross section σ 0 in a theoretical distribution dN/dE, that the total number of events observed in our data is equal to a certain value or less. If we are conservative and assume no knowledge of the background distribution and therefore that all observed events are signal, then an upper limit at some desired confidence level may be set by adjusting σ 0 in dN/dE until the total number of events µ expected, given by integrating dN/dE over the whole experimental range, is such that it satisfies equation 4.</p>

				<figure>
					<trash>α = e −µ N m=0 µ m m! (4)</trash>


				</figure>

				<p>Here, 1−α is the confidence level of the upper limit set in this way, and N is the number of observed data events. In order to incorporate knowledge of expected backgrounds into equation 4, we must use a modified form of this relation that assumes the overall normalization of the background , which is often poorly understood in dark matter direct detection experiments (for instance, see equation 32.35 in [15]). The most conservative approach is to assume no knowledge of the backgrounds, and so all events are signal candidates. In this case, any observed events considerably degrade the upper limit obtained with equation 4. This is particularly true for scenarios in which a background fills a small subset of the full experimental acceptance. For nuclear recoil signals, as the energy detection threshold is lowered, the sensitivity to backgrounds increases. Background events observed near detection threshold are counted with the same significance as events in higher recoil energy sub-intervals of the experimental acceptance. Direct dark matter detection experiments gain sensitivity to WIMP events by lowering their energy thresholds, since the WIMP-nucleon interaction rate is expected to peak at low nuclear recoil energies. In this scenario, the Poisson method can lead to overly conservative upper limits on the WIMP-nucleon interaction cross section, in the presence of backgrounds.</p>

			</div>
			<div>
				<head>B. Maximum Gap Method</head>

				<p>For a given σ 0 , the &quot; gap &quot; for a pair of data points is defined to be [6] x i =</p>

				<figure>
					<trash>Ei+1 Ei dN dE (σ 0 )dE (5)</trash>


				</figure>

				<p>where x i is the value obtained by integrating dN/dE between the observed energy values [E i , E i+1 ] for i = 0, .., N (see figure 1 in [6]) and E 0 and E N +1 are the lower and upper recoil energy experimental thresholds. A set of N recoil energy measurements yields an (N − 1)- dimensional vector x of gaps. The &quot; maximum gap &quot; for a set of N recoil energy measurements is defined to be the largest member of the set of all gaps that can be computed from the data. This quantity depends on an integral over the hypothesized theoretical distribution, and through that integral, on the WIMP interaction cross section σ 0 . The larger the maximum gap given a σ 0 , the larger the discrepancy between the number of points observed in data and the number of points expected. Therefore , the maximum gap allows a powerful statistical test between the measured data and the normalization of the theoretical signal distribution. To set a limit, we are interested in the probability, given a value of the cross section σ 0 in a theoretical distribution dN/dE, that the maximum gap for a given set of data is equal to a certain value or less. This is described by the CDF of the maximum gap, and can be analytically calculated [6],</p>

				<figure>
					<trash>C 0 (x, µ) = m k=0 (kx − µ) k e −kx k! 1 + k µ − kx (6)</trash>


				</figure>

				<p>where µ is the total number of events expected in the experimental range (dN/dE integrated from lower to upper limit energy threshold), and m is the greatest integer ≤ µ/x. An upper limit at a given confidence level is obtained from equation 6 by adjusting the input cross section σ 0 until the function C 0 above, evaluated at the maximum gap of the data, yields 0.90. The interpretation is that in an ensemble of experiments, on each of which the upper limit setting technique is employed, 90% will obtain an upper limit greater than σ 0 .</p>

			</div>
			<div>
				<head>C. Discussion of Limit Setting Techniques</head>

				<p>The maximum gap statistic possesses a number of nice qualities, particularly in the presence of background, which motivate the generalization of the method to two dimensions for directional dark matter detection experiments . We summarize the main results here; see [6] for a rigorous discussion. First, the maximum gap is unchanged under a one-one transformation of the variable in which the events are distributed . This can be seen by making a transformation from recoil energy in the above discussion to a variable ρ such that ρ is equal to the total number of events expected between the point E and the lower energy threshold . In ρ, equation 1 is a uniformly distributed, unit density function. This calculation is treated in more detail in Appendix I. This means that the maximum gap does not depend on the form of the theoretical distribution.</p>

				<p>Second, the method can be used for an arbitrarily large number of observed data points, and requires no binning of the data points. Most importantly, this statistic provides a conservative upper limit on the true WIMP cross section that can considerably out-perform the Poisson upper limit setting technique.</p>

				<p>In WIMP detection experiments there are often low energy backgrounds from processes which are difficult to model accurately with simulations, such as MeV-scale neutron interactions or 238 U and 232 Th decay progeny in the detector materials. It is unlikely that the measured maximum gap will be found in an interval of an experiment&apos;s acceptance that contains both signal WIMP events and a large number of background events.</p>

				<p>The presence of sizable background would significantly shorten the gap sizes expected from signal alone. We thus expect the maximum gap to occur in the data in an interval where the background does not dominate. In this way, the maximum gap method automatically selects recoil energy intervals that are characteristic of the expected WIMP signal alone. Another striking advantage of the maximum gap method is that, for a fixed gap size, it is independent of the total number of events observed. In the Poisson case, each additional point observed inflates the upper limit an experimenter sets on their data. On the other hand, if an experimenter observes a large gap in their data, the limit set on that data is unchanged if the number of points observed outside of the maximum gap is one or one million.</p>

			</div>
			<div>
				<head>IV. A NEW DARK MATTER STATISTIC FOR TWO DIMENSIONS</head>

				<p>For directional dark matter detection experiments, it is desirable to preserve the benefits of the maximum gap method for setting upper limits. Towards this end, we need to generalize the method to two dimensions. We consider a series of measurements {(E 1 , cos(ψ) 1 ), ..., (E N , cos(ψ) N )}, where N is the total number of measurements of the energy of nuclear recoils E, and ψ is the nuclear recoil angle in a dark matter detection experiment measured from the vector pointing from the constellation Cygnus to the Earth in the detector lab frame. In general, the two-dimensional rate will be given by a function d 2 N ( λ)/d(cos(ψ))dE, where the λ are the theoretical parameters of the model. As in one dimension, the model for the two-dimensional differential WIMP-nucleon interaction rate, equation 3, under standard dark matter halo assumptions, depends only on σ 0 , the true WIMP interaction cross section. In the following we describe an algorithm for obtaining general, multidimensional CDFs, focusing on the two-dimensional case. We then apply the usual prescription for setting upper limits, varying σ 0 , and find that our two-dimensional limit setting technique has the correct 90% coverage.</p>

			</div>
			<div>
				<head>A. Monte Carlo Generated Cumulative Distribution Functions</head>

				<p>To calculate the CDFs for an arbitrary statistic of interest (SI), we simplify matters by asking an easier question than &quot; what is the probability that the SI is less than or equal to a certain value &quot; and instead ask &quot; what is the probability that, given an observation of N events, the SI is less than or equal to a certain value. &quot; The advantage of the latter question is that it can be addressed with Monte Carlo methods, and leads naturally to the resolution of the first question.</p>

				<p>We start by generalizing the one-dimensional case. The theoretical distribution in equation 1, assuming a value for σ 0 , gives a concrete form for dN/dE, the expectation for how the observed events are distributed in nuclear recoil energy. Then, we draw N events from this distribution . We compute the value of the SI on this fake data, whether it be the maximum gap of the distribution, or some other SI. We repeat this procedure many times, until we have an SI frequency distribution, given N observed events. We do this in turn for N = 1, 2, ..., N max stopping for N max so large that the Poisson probability (equation 8) for observing N max events is negligible. This results in an array h = {h 0 , ..., h Nmax } of histograms, where h 0 is the frequency plot of the SI given the observation of zero events, h 1 is the frequency plot of the SI given the observation of one event, etc.</p>

				<p>In each of the h i , i = 1, ..., N max , we have N toys entries , where N toys is the number of toy experiments, for each number of observed events, that we performed. By normalizing each of the h i by N toys , we obtain the probability distribution of the SI, for each of the i events observed subclasses considered. The resulting normalized vector of histograms can be properly interpreted as the probability distribution functions (PDFs) of the SI h = h/N toys .</p>

				<p>For setting an upper limit, we need the CDFs of the SI.</p>

				<p>To construct these, we take each histogram member h i of h in turn and create a new histogram, ˆ h c,i , assigning to each bin b ′ mi of h c,i the value given in equation 7, where b ki is the k th bin of h i , and k and m index the bins of the PDF and CDF histograms, respectively.</p>

				<figure>
					<trash>b ′ mi = m k=1 b ki (7)</trash>


				</figure>

				<p>For convenience, 500 bin CDF and PDF histograms were generated for the maximum gap studies in this paper, and 300 bin CDF and PDF histograms were generated for the maximum patch studies.</p>

				<p>In this way we numerically turn each of the PDFs in h into a CDF in h c for the SI. Now we havê h c , a vector of CDFs, each corresponding to a number of observed events. The probability of observing a certain number of events is determined by the Poisson probability of observing N events given µ total events,</p>

				<figure>
					<trash>P (µ, N ) = µ N N ! e −µ . (8)</trash>


				</figure>

				<p>In order to construct the full CDF of the SI for the input theoretical distribution dN (σ 0 )/dE, we add all of the histograms in h c together, weighting each by the probability in equation 8 for seeing that number of events. This yields the following equation for the Monte Carlo generated CDF for the SI,</p>

				<figure>
					<trash>C SI (x SI , µ) = Nmax k=0 h c,k (x SI ) µ k k! e −µ (9)</trash>


				</figure>

				<p>Here x SI is the value of the SI at which we want to know the value of the CDF, and µ is the total number of events expected in the experimental range. The notation h c,k (x SI ) means to evaluate the value of the k th histogram in thê h c vector of SI CDFs at x SI . This can be done in a number of different ways; we can take this as the height of the bin in h c,k that x SI falls into (thereby obtaining a discrete CDF), or, perform a bin-to-bin interpolation , thus turning thê h c,k &apos;s into smooth functions of x SI . In the results presented in this paper, thê h c,k histograms are interpolated using splines. We have now in equation 9 manufactured the analogue to equation 6 for the maximum gap statistic for an arbitrary SI. Note however that for the maximum gap statistic this discussion is unnecessarily complicated because the maximum gap is unchanged under a one-one transformation of the theoretical distribution dN/dE in E, as shown in Appendix I. This property allows one to transform any distribution into a unit density, uniformly distributed function. Thus whenever we change σ 0 for the maximum gap statistic, we need not draw events from a different distribution, we may instead always use a unit density, uniform distribution. We validate the Monte Carlo CDF generating scheme by comparing the frequency distribution of upper limits resulting from the Monte Carlo version of the maximum gap method with the result obtained using the analytic CDF in equation 6. We find that the results agree within numerical errors.</p>

			</div>
			<div>
				<head>B. Maximum Patch Method</head>

				<p>Analogously to the one-dimensional gap, we may construct a &quot; patch &quot; as a subset of an experiment&apos;s total acceptance , which is determined by (E 0 , cos(ψ) 0 ), the energy and angle lower limit experimental threshold of measurement , and (E N +1 , cos(ψ) N +1 ), the energy and angle upper limit experimental threshold of measurement. We define a patch for a set of N data points to be</p>

				<figure>
					<trash>y ijk = cos(ψ)j cos(ψ) k Ei+1 Ei d 2 N d(cos(ψ))dE (σ 0 )dEd(cos(ψ)) (10)</trash>


				</figure>

				<p>where i ranges from 0 to N and j and k range, independently , from 1 to N . We require that cos(ψ) j &gt; cos(ψ) k and that E i &lt; E j &lt; E i+1 and E i &lt; E k &lt; E i+1 . We also include the additional patch candidate not picked up by this prescription for every i; namely that one which has as its borders in cos(ψ) the upper and lower angular limits [cos(ψ) 0 , cos(ψ) N +1 ]. Equation 10 describes rectangular patches, whose limits are [E i , E i+1 ] in E and [cos(ψ) k , cos(ψ) j ] (plus [cos(ψ) 0 , cos(ψ) N +1 ]) in cos(ψ). Some of the rectangles described by equation 10 may have points inside their boundaries; these are disqualified from being maximum patches, for the same reason that gaps with points in them are disqualified in the maximum gap method. In principle any two-dimensional shape can be used to define a patch; we have chosen to use rectangles for ease of computation. It is possible that sensitivity could be gained in this method by considering patch geometries other than rectangles. To set an upper limit we are interested in the maximum value that y ijk takes in equation 10 for all acceptable values of j, k and i. The situation is illustrated in figure 1, where the spikes are Monte Carlo generated fake data points in E and cos(ψ) (4 in total) and the smooth curve represents d 2 N (σ 0 )/d(cos(ψ))dE for a given cross section value. The maximum patch candidate in this example has boundaries that extend from the lower to the upper cos(ψ) threshold, and from 5 − 15 keV . Note that this particular maximum patch candidate is also a maximum gap candidate in E-space.</p>

				<p>Our algorithm for computing the maximum patch on a set of observed two-dimensional data points is described in detail in Appendix II. An example of the patch-finding algorithm for 1 observed event is shown in figure 2. Once the maximum patch is found, one calculates the PDFs and sums them, appropriately weighted, to produce the CDFs as in section IV A. Figure 3 shows the resulting CDF for several expected numbers of events µ.</p>

				<p>We note that we are able to use an analogue to the simplified CDF generation scheme mentioned at the end of IV A for the maximum gap method, with one important change. Unlike the maximum gap statistic, the maximum patch is not unchanged under a one-one transformation of the theoretical distribution, d 2 N/d(cos(ψ))dE, in E and cos(ψ). Therefore, to set limits on data distributed according to d 2 N/d(cos(ψ))dE with CDFs generated from a unit density, uniformly distributed function , one must use the transformation given in Appendix C of [16]</p>

				<figure>
					<figDesc>.</figDesc>
					<trash>E [k e V ] 0 5 10 15 20 25 ) ψ C o s ( -1 -0.5 0 0.5 1 ] -1 day -1 kg -1 ))dE [keV ψ N/d(cos( 2 d 0 0.2 0.4 0.6 0.8 1 FIG. 1: An illustration of a maximum patch candidate. The spikes are hypothetical measured data points in an experiment , and the smooth curve is, for some assumed cross section , the expected distribution of signal between the two lowest energy data points. The volume under the curve is one of the y ijk &apos;s of equation 10 for this dataset, and thus a maximum patch candidate. Note that if we project the data points and theoretical distribution onto the energy interval, this is also a maximum gap candidate in the nuclear recoil energy dimension</trash>


				</figure>

				<p><formula>. 1 x 0 1 2 x 0 1 1 x 0 1 2 x 0 1 1 x 0 1 2 x 0 1 1 x 0 1 2 x 0 1</formula></p>

				<p>FIG. 2: An example illustrating the maximum patch algorithm for 1 assumed data point in the experimental acceptance . If the data point is not on one of the four boundaries , there are four patches that contribute. Our algorithm is detailed in Appendix II; the order in which our algorithm computes the above maximum patch candidates is upper left, upper right, lower left and lower right. C. The Recipe The recipe for the experimenter wishing to use the maximum patch method to set an upper limit on the dark matter cross section in her experiment is as follows, assuming a measurement of a vector of N</p>

				<figure>
					<trash>two-dimensional data points D = {(E 1 , cos(ψ) 1 ), ..., (E N , cos(ψ) N )}. We take as an explicit example a direction sensitive dark matter direct detection experiment in this recipe, but this method can be used for any two-dimensional dataset for ) µ (patch size/ 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 % CL 0 10 20 30 40 50 60 70 80 90 100 =10 µ =5 µ =3 µ =2 µ =1 µ FIG. 3</trash>


				</figure>

				<p>: Cumulative probability distribution functions (CDFs) for various total expected numbers of events µ in the experimental acceptance (equation 9 for the maximum patch SI, equation 10). A horizontal line is drawn at the 90% confidence level. So, for instance, for µ = 5, 90% of the time, the maximum patch of a toy signal experiment will be less than ≈ 4. which the distribution of the signal is known. 1. Given a predicted two-dimensional rate d 2 N (σ 0 )/d(cos(ψ))dE, the experimenter calculates the maximum patch of their data for some starting value σ 1 for the WIMP-nucleon interaction cross section by applying the recipe for calculating the maximum patch of a set of two-dimensional data points outlined in Appendix II. 2. The experimenter then must evaluate equation 9 for the case where the statistic of interest is the maximum patch. The maximum patch CDF for µ total expected events can either be calculated by following the Monte Carlo procedure outlined in section IV A or by referencing the tables provided at the end of this paper in Appendix III.</p>

			</div>
			<div>
				<head>3.</head>

				<p>Evaluating equation 9 at the maximum patch of the data yields the confidence level at which σ 1 is an upper limit on the WIMP-nucleon interaction cross section. If this is less (more) than the confidence level desired, the cross section guess is increased (decreased) to a new guess σ 2 . The experimenter again calculates the maximum patch of the data for this assumed cross section and then, via equation 9, calculates the CL at which σ 2 is an upper limit on the WIMP-nucleon interaction cross section. This procedure is iterated for as many guesses σ N as required to set the desired confidence level upper limit on the WIMP-nucleon cross section for the data. D. Validation of the Maximum Patch Method We validate the maximum patch prescription described above by checking that the coverage of our upper limit setting technique is correct. To do this, we generate many ensembles of toy Monte Carlo experiments, each with different WIMP-nucleon interaction cross sections, and with signal events distributed according to equation 3. We set an upper limit on each toy experiment using the maximum patch technique. Note that to test coverage at the 90% confidence level, we must choose cross sections that yield an expected number of events µ &gt; 2.3026. Below this, no cross section upper limit can be set with a confidence level as high as 90% (see figure 3). For each input cross section σ 0 , and the associated total number of events µ, we perform 10,000 toy experiments, where the observed number of events is Poisson-distributed about µ, and (E, cos(ψ)) for the events are distributed according to equation 3. For each ensemble of 10,000 experiments with different input σ 0 &apos;s, we record the percentage of the time our upper limit is higher than σ 0 . For an upper limit requested at 90% CL, the percentage should be 90% within statistical errors, which is the definition of correct coverage. The results of this study, for σ 0 &apos;s such that µ = 1, ..., 30 are shown in figure 4. The stepping behaviour observed in the Poisson limit coverage is expected, due to the discrete nature of the statistic. Figure 4 also shows the coverage computed in this way for the maximum gap method (with the CDFs computed via our Monte Carlo technique) and the Poisson method. All methods are observed to have the correct coverage, within statistical and numerical errors.</p>

				<figure>
					<trash>number of signal events 0 5 10 15 20 25 30 % CL 75 80 85 90 95 100 105 poisson max gap max patch FIG. 4</trash>


				</figure>

				<p>: For toy Monte Carlo experiments with pure signal events, the coverage as a function of signal events for the maximum gap, maximum patch and Poisson methods. This demonstrates that our upper limit setting methods have the correct coverage, within statistical errors for µ &gt; 2.23026, as expected. Each point in this plot corresponds to 10,000 MC toy experiments. The errors shown are statistical.</p>

			</div>
			<div>
				<head>V. COMPARISON OF METHODS</head>

				<p>Having built the maximum patch method, we compare it to various other methods for setting upper limits, in several circumstances of interest. Our goal is to highlight the impact of directionality for dark matter direct detection experiments. Unless otherwise stated, for the various comparisons in this paper we arbitrarily assume a WIMP mass of 60 GeV, and we use the Xenon10 experiment&apos;s acceptance and target properties [4] to construct limits (ignoring subtleties like quenching factors, form factors and efficiencies). First, in the absence of background and with a sizable signal, we would like to verify that the maximum patch method has not only the same coverage as the Poisson method (see subsection IV D) but also that its performance is comparable as a method for setting upper limits. Towards this end, we employ the ensembles of 10,000 toy Monte Carlo experiments from subsection IV D, recording the median upper limit obtained by the maximum patch, maximum gap and Poisson methods as a function of µ for each 10,000 event sub-sample generated with a different input σ 0 . This comparison is shown in figure 5. Figure 6 shows the frequency distribution of</p>

			</div>
			<div>
				<head>number of signal events</head>

				<p><formula>0 5 10 15 20 25 30 0 σ / median σ 1 1.5 2 2.5 3 3.5 4 4.5 5 poisson max gap max patch</formula></p>

				<p>FIG. 5: The median upper limit cross section obtained by our implementation of the Poisson, maximum gap and maximum patch procedures divided by the true input cross section σ0 as a function of input cross section (and thereby, as a function of the total number of expected events in the experimental interval). Each point in this plot corresponds to 10,000 MC toy experiments. per limits set by the maximum gap, maximum patch and Poisson methods on the 10,000 event ensemble with an input σ 0 such that a total of µ = 7 signal events are expected . These three distributions are used to generate the µ = 7 point in both figure 5 and figure 4. The computed coverages in figure 6 for the maximum gap, maximum patch and Poisson methods are (90±1)%, (90±1)% and (92 ± 1)%, respectively, which is correct, within statistical errors. We note that in the case of pure signal, the Poisson method outperforms the maximum gap and maximum</p>

				<p><formula>] 2 [cm UL σ 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 -39 10 × exp N 1 10 2 10 3 10 4 10 5 10</formula></p>

				<p>poisson max gap max patch σ input FIG. 6: The frequency distribution of upper limits σUL obtained by applying the Poisson, maximum gap and maximum patch procedures to 10,000 toy Monte Carlo experiments with an input cross section σ0 shown as a black line on the graph. σ0 was chosen to yield 7 total expected events in the experimental interval. The percent of the time that our procedure for each method sets a correct upper limit (a limit above the true input cross section σ0) is (90 ± 1)%, (90 ± 1)% and (92±1)% for the maximum gap, maximum patch and Poisson methods, respectively.</p>

				<p>patch methods by a factor of ≈ 1.2. This is expected; the maximum gap procedure has already been demonstrated to give looser upper limits than the Poisson method in the case of pure signal (see [6], figure 3(a)). This could be resolved, as in [6] by considering gaps containing greater than zero events, which is termed the optimal gap method. The extension of the optimal gap approach to two dimensions is not considered here. We also note that little sensitivity is gained by using the maximum patch method versus the maximum gap method in the case of pure signal.</p>

				<p>Realistically, WIMP direct detection experiments have backgrounds, and so a more interesting comparison is how the maximum gap, maximum patch and Poisson methods do in the presence of sizable backgrounds. For this test, we populate the lower half of our nuclear recoil energy range, and the lower half of our nuclear recoil angular range, with a background drawn according to a flat distribution. We caution that all of our results including background events are highly dependent on this particular background distribution choice. Figure 7 shows the frequency distribution of upper limits obtained by applying the maximum gap method, the maximum patch method, and the Poisson method to 10,000 toy experiments generated in this way with a total number of expected background events of 7, and a total expected number of WIMP signal events of 5. The coverage is (100 ± 1)%, (95 ± 1)% and (100 ± 1)% for the maximum gap, maximum patch and Poisson methods respectively, which is not at the confidence level requested due to the presence of the large background. The median 90% confidence level upper limit cross sections, from the maximum gap, maximum patch and Poisson techniques are compared in figure 8, as a function of the total number of expected input background events µ = 1, 2, ..., 30 (with 5 expected signal events in each toy experiment).</p>

				<p>The total number of background events in a given Monte Carlo experiment, like the total number of signal events, is drawn randomly from a Poisson distribution with the mean given by the total number of expected events. Figure 8 shows that in the presence of a sizable WIMP signal, the maximum patch procedure provides stronger upper limits than the Poisson or maximum gap procedures as the amount of background contamination increases . The Poisson method does so poorly because it uses only the total number of events to set upper limits, assuming that they are all signal, yielding an increasingly inflated upper limit as the number of background events injected into the toy experiments increases. The maximum patch method outperforms the maximum gap procedure because it includes an extra dimension in which signal and background are differently distributed. The observation that the maximum gap and maximum patch limits seem to asymptotically flatten is due to the overly simplistic background chosen for these studies; eventually the maximum patch or gap is always outside of the lower E interval or E − cos(ψ) quadrant, and thus characteristic only of the WIMP-signal input which, within statistical fluctuations, is identical outside of the lower E interval or E − cos(ψ) quadrant as the backgrounds are confined there.</p>

				<p><formula>] 2 [cm UL σ 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 -39 10 × exp N 1 10 2 10 3 10 4 10 5 10</formula></p>

				<p>poisson max gap max patch σ input FIG. 7: The frequency distribution of upper limits σUL obtained by applying the Poisson, maximum gap and maximum patch procedures to 10,000 toy Monte Carlo experiments with an input cross section σ0 shown as a black line on the graph. σ0 was chosen to yield 5 total expected signal events in the experimental interval. Background events were included in these experiments with a uniform distribution in the lower half of the recoil energy and recoil angle experimental acceptance . For this plot, the total number of expected background events was set at 7. The percent of the time that our procedure for each method sets a correct upper limit (a limit above the true input cross section σ0) is (100 ± 1)%, (95 ± 1)% and (100 ± 1)% for the maximum gap, maximum patch and Poisson methods, respectively.</p>

				<p>The most probable situation in current dark matter</p>

			</div>
			<div>
				<head>number of background events</head>

				<p><formula>0 5 10 15 20 25 30 0 σ / median σ 1 2 3 4 5 6 7 8 9 10 poisson max gap max patch</formula></p>

				<p>FIG. 8: The median upper limit cross section obtained by our implementation of the Poisson, maximum gap and maximum patch procedures divided by the true input cross section σ0 as a function of background events injected into our toy experiments , uniformly distributed in the lower half recoil energy and recoil angle interval. The point at number of background events equals 7 comes from dividing the medians of the frequency distributions in figure 7 by the true input cross section for the Poisson, maximum gap and maximum patch limit setting procedures. Each point in this plot corresponds to 10,000 MC toy experiments and has, in addition to background, a signal component generated with a cross section corresponding to 5 total expected signal events. experiments is that the true cross section lies well below the detectable range. To study this scenario, we perform 10,000 toy experiments as above, with σ 0 = 1 × 10 −46 cm 2 (or ≈ 0 total expected signal events), and the same distributions of background events as in figures 7 and 8 (flat in the E − cos(ψ) plane, and confined to the lower E − cos(ψ) quadrant). Figure 9</p>

				<figure>
					<figDesc>shows the frequency distribution of upper limits obtained by applying the maximum gap method, the maximum patch method, and the Poisson method to 10,000 toy experiments with an expected number of background events of 7 and negligible signal. The coverage is (100 ± 1)%, (100 ± 1)% and (100 ± 1)% for the maximum gap, maximum patch and Poisson methods, respectively, which is not at the confidence level requested due to the presence of a large background and no signal. The median 90% confidence level upper limit cross sections, from the maximum gap, maximum patch and Poisson techniques are compared in figure 10 as a function of input background events in the case of negligible signal. In the presence of a negligible WIMP signal and increasing backgrounds, the maximum patch procedure provides by far the most restrictive upper limit as the amount of background contamination increases. From figure 10 it is clear that the Poisson method limit is not competitive as the number of backgrounds increases, and the maximum patch method outperforms the maximum gap method by at least a factor of 2 for more than 1 expected background events for this particular background</figDesc>

				</figure>

				<p><formula>distribution. ] 2 [cm UL σ 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 -39 10 × exp N 1 10 2 10 3 10 4 10 5 10</formula></p>

				<p>poisson max gap max patch σ input FIG. 9: The frequency distribution of upper limits σUL obtained by applying the Poisson, maximum gap and maximum patch procedures to 10,000 toy Monte Carlo experiments with an input cross section σ0 = 1 × 10 −46 shown as a black line on the graph, chosen to give ≈ 0 events for the Monte Carlo toy exposures. Background events were included in these experiments with a uniform distribution in the lower half of the recoil energy and recoil angle experimental acceptance. For this plot, the total number of expected background events was set at 7. The percent of the time that our procedure for each method sets a correct upper limit (a limit above the true input cross section σ0) is (100 ± 1)%, (100 ± 1)% and (100 ± 1)% for the maximum gap, maximum patch and Poisson methods, respectively.</p>

				<figure>
					<trash>number of background events 0 5 10 15 20 25 30 0 σ / median σ 1000 1500 2000 2500 3000 3 10</trash>


				</figure>

				<p>× poisson max gap max patch FIG. 10: The median upper limit cross section obtained by our implementation of the Poisson, maximum gap and maximum patch procedures divided by the true input cross section σ0 as a function of background events injected into our toy experiments, uniformly distributed in the lower half recoil energy and recoil angle interval for a negligible input signal cross section. The point at number of background events equals 7 comes from dividing the medians of the frequency distributions in figure 9 by the true input cross section for the Poisson, maximum gap and maximum patch limit setting procedures. Each point in this plot corresponds to 10,000 MC toy experiments.</p>

				<p>In typical dark matter detection experiments, upper limits on the WIMP-nucleon cross section are reported as a function of WIMP mass. In order to compare the performance of the maximum gap, maximum patch and Poisson methods of setting upper limits as a function of WIMP mass, we generated 10,000 Monte Carlo toy datasets at a variety of different WIMP masses. Adopting the likely scenario for a given dark matter experiment , we hypothesize a WIMP-nucleon interaction cross section of σ 0 = 1 × 10 −46 for these toy experiments and a background with an average number of events equal to 10 (again, flat in the E − cos(ψ) plane, and confined to the lower E − cos(ψ) quadrant). The result of this study is the three limit curves in figure 11.</p>

				<figure>
					<figDesc>The solid bands represent the RMS widths of the upper limit frequency plots (much like figures 9, 7 and 6) obtained on the 10,000 experiments at each given mass point. The shape of the maximum gap limits at low WIMP masses is an artifact of the background choice. For low WIMP masses, the maximum patch method is by far the most sensitive to the cross section (between ≈ 10 − 100 GeV) with a very small RMS. At higher WIMP masses, the difference between the maximum gap and maximum patch limit techniques diminishes, but both consistently outperform the Poisson limit setting method. We note that the studies in this paper are all based on one assumed background shape. Different background distributions will lead to different results.</figDesc>

				</figure>

			</div>
			<div>
				<head>WIMP Mass [GeV]</head>

				<figure>
					<trash>2 10 3 10 4 10 0 σ / median σ 6 10 7 10 8 10 9 10 poisson max gap max patch</trash>


				</figure>

				<p>FIG. 11: The median upper limit cross section obtained by our implementation of the Poisson, maximum gap and maximum patch procedures divided by the true input cross section σ0 as a function of assumed WIMP mass, with 10 background events on average that are uniformly distributed in the lower half recoil energy and recoil angle interval for a negligible input signal cross section. Each point in this plot corresponds to 10,000 MC toy experiments. The bands correspond to the RMS widths of the upper limit frequency distributions obtained using the Poisson, maximum gap and maximum patch methods, respectively, at each mass point sampled.</p>

			</div>
			<div>
				<head>VI. CONCLUSIONS</head>

				<p>In this paper, we have developed a new method for setting upper limits in two dimensions. The motivation for our maximum patch method is directional dark matter detection, but it is generally applicable to any twodimensional data sets for which the distribution of the signal is known. The approach is an extension of the onedimensional maximum gap method [6], a statistic often used to set limits on the WIMP-nucleon interaction cross section in direct detection dark matter experiments. To directly detect dark matter requires unprecedented control and understanding of backgrounds. The great advantage of the maximum gap and patch methods is that they require no knowlege of the background distribution to set conservative upper limits on the WIMP nucleon scattering cross section. The scattering kinematics of a dark matter signal in one and two-dimensional direct detection experiments are relatively simple. This information is included in a straightforward way in the maximum gap and patch methods. In particular, the maximum patch method incorporates information about the large expected angular anisotropy of dark matter scattering into the limit setting procedure. We demonstrate that for simplistic background assumptions, the maximum patch method and two-dimensional dark matter detection yield a large gain in sensitivity, especially at low WIMP masses, over one-dimensional dark matter detec- tion.</p>

			</div>
			<div>
				<head>Appendix I</head>

				<p>Our goal is to prove, in detail, the assertion in [6] that the maximum gap is unchanged under a one-one transformation of the variable in which the events are distributed, and thus that the maximum gap is independent of the particular way in which the events are distributed for a given σ 0 in one dimension (by dN (σ 0 )/dE). The total number of events in the experimental window is given by µ, where</p>

				<figure>
					<trash>µ = +∞ −∞ dE dN dE . (11)</trash>


				</figure>

				<p>Here, if E is outside of the experimental thresholds, dN/dE = 0, and dN/dE is strictly positive.</p>

				<p>We wish to change variables from E in equation 11 to ρ, where ρ [6]</p>

				<figure>
					<trash>is ρ(E) = E −∞ dE ′ dN dE ′ (12) By the chain rule, dN dρ = dN dE dE dρ (13)</trash>


				</figure>

				<p>and dE/dρ=(dρ/dE) −1 . dρ/dE from equation 12 is then given by the fundamental theorem of calculus to be</p>

				<figure>
					<trash>dρ dE = d dE E −∞ dE ′ dN dE ′ = dN dE (E) (14) Thus, equation 13 implies that dN dρ = dN dE dρ dE −1 = dN dE dN dE = 1 (15)</trash>


				</figure>

				<p>and that in the new variable ρ, the differential rate is a unit density function, of length µ.</p>

			</div>
			<div>
				<head>Appendix II</head>

				<p>Our method for calculating the maximum patch is as follows. A similar scheme is put forth in [16]. Call the set of measured two-dimensional data points on which we wish to determine the maximum patch, D = {(E 1 , cos(ψ) 1 ), ..., (E N , cos(ψ) N )}, where as above, (E 0 , cos(ψ) 0 ) and (E N +1 , cos(ψ) N +1 ) we define to be the upper and lower recoil energy and recoil angle thresholds of our experiment.</p>

			</div>
			<div>
				<head n="1">Order</head>

				<p>D in E. Call the new, E-ordered vector D ′ . 2. Loop through the intervals [E i , E j ] in D ′ such that i runs from 0 to N + 1 and j runs from i + 1 to N + 1.</p>

			</div>
			<div>
				<head>3.</head>

				<p>Inside each E interval in this loop, if there are no points with an E k such that E i &lt; E k &lt; E j , then compute equation 10 with E limits [E i , E j ] and cos(ψ) limits [cos(ψ) 0 , cos(ψ) N +1 ]. 4. If there are N p points with an E k such that E i &lt; E k &lt; E j , make a list of them, P = {(E 0 , cos(ψ) 0 ), ..., (E k , cos(ψ) k ), ..., (E N +1 , cos(ψ) N +1 )} of length N p + 2, ordered in E, adding the points (E 0 , cos(ψ) 0 ) and (E N +1 , cos(ψ) N +1 ) (the threshold points -that&apos;s where the +2 comes from in the total number of points in P ) to the front, and back of the list, respectively. Order P by E, calling the new Eordered vector P ′ . Then loop through the intervals [cos(ψ) P ′ ,m , cos(ψ) P ′ ,n ], in P ′ such that m runs from 0 to N p + 2 and n runs from m + 1 to N p + 2, where the subscript (P ′ , m) denotes the m th member of the ordered vector P ′ . Each iteration of this loop will provide a maximum patch candidate with E limits [E i , E j ] and cos(ψ) limits [cos(ψ) P ′ ,m , cos(ψ) P ′ ,n ]. 5. For each of these candidates, check to see if there is a point D ′ d in D ′ such that E i &lt; E d &lt; E j and cos(ψ) P ′ ,m &lt; cos(ψ) d &lt; cos(ψ) P ′ ,n . If so, then there is a point inside our patch candidate, which means it is not a maximum patch candidate; throw it out. 6. If a maximum patch candidate has passed all of the above criterion, stick it in a vector of some arbitrary length y. This vector exhausts all possible rectangles in the two-dimensional E-cos(ψ) plane. 7. To find the maximum patch of the data, loop through all of the elements y i of y, and store the largest y i value; this is the maximum patch.</p>

			</div>
			<div>
				<head>Appendix III</head>

				<p>Tables I and II below record thê h c,k (x SI )&apos;s of the maximum patch statistic for k = 1, ..., 100 ( ˆ h c,0 (x SI ) is 0 for all maximum patch values except for the patch equal to the total number of expected events). The maximum patch CDF is computed by interpolating these points into smooth curves and using them to evaluate equation 9. Note that the smoothed curves obtained from the tables are functions of (y/µ), the maximum patch value divided by the total number of expected events. The work in this paper was done using 200 CDFs in the sum of equation 9.</p>

				<p>In Tables I and II, a deviation from a cumulative probability of 100% for (y/µ) = 1 is observed at the 0.1% level for µ = 67 and greater. The reader is advised to use the tables below only for µ = 50 or less, where they have been verified to give correct coverage at the 1% level.</p>

				<p>The reader is cautioned that these tables were generated using a unit density, uniformly distributed theoretical function as input, and thus cannot be directly applied, as in the maximum gap case, to data to obtain an upper limit. The data must be transformed such that it is uniformly distributed assuming a given model as its true distribution. The necessary transformation can be found in Appendix C of [16]. This subtlety can be avoided by generating a set of CDFs for every parameter change in the theoretical model considered for the data, but in most applications this will be prohibitively computationally intensive.</p>

				<p>TABLE I: Table of maximum patch CDF&apos;s (thê h c,k (xSI)&apos;s of section IV A) given an observation of n = 1, ..., 54 events. These values of the CDFs are given as a function of the observed maximum patch divided by the total expected number of events. Upper limits can be set on two-dimensional data with these tabulated CDFs following the recipe laid out in section IV C. (y/µ) n=1 n=2 n=3 n=4 n=5 n=6 n=7 n=8 n=9 n=10 n=11 n=12 n=13 n=14 n=15 n=16 n=17 n=18</p>

				<figure>
					<trash>≤ 0.17 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.20 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.002 0.004 0.006 0.013 0.022 0.038 0.24 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.003 0.008 0.017 0.030 0.056 0.093 0.141 0.192 0.251 0.28 0.000 0.000 0.000 0.000 0.000 0.000 0.003 0.011 0.024 0.047 0.081 0.131 0.188 0.263 0.339 0.420 0.483 0.556 0.32 0.000 0.000 0.000 0.000 0.002 0.012 0.034 0.071 0.119 0.189 0.271 0.359 0.447 0.534 0.606 0.679 0.735 0.786 0.36 0.000 0.000 0.000 0.005 0.024 0.063 0.121 0.199 0.292 0.409 0.509 0.596 0.676 0.748 0.796 0.836 0.878 0.907 0.40 0.000 0.000 0.007 0.034 0.091 0.170 0.283 0.395 0.505 0.627 0.706 0.768 0.828 0.869 0.902 0.930 0.956 0.969 0.44 0.000 0.003 0.030 0.102 0.204 0.318 0.464 0.583 0.679 0.775 0.842 0.884 0.920 0.948 0.965 0.976 0.986 0.992 0.48 0.000 0.015 0.083 0.204 0.345 0.481 0.619 0.730 0.814 0.875 0.924 0.950 0.969 0.980 0.987 0.993 0.997 0.997 0.52 0.003 0.056 0.171 0.324 0.491 0.631 0.749 0.841 0.895 0.936 0.965 0.979 0.986 0.991 0.996 0.997 0.998 0.999 0.56 0.017 0.115 0.276 0.448 0.628 0.755 0.843 0.911 0.943 0.969 0.983 0.990 0.993 0.997 0.998 0.999 1.000 1.000 0.60 0.042 0.190 0.400 0.578 0.732 0.838 0.911 0.951 0.973 0.987 0.994 0.996 0.997 0.999 0.999 1.000 1.000 1.000 0.64 0.080 0.286 0.518 0.691 0.817 0.902 0.954 0.975 0.987 0.993 0.997 0.998</trash>


				</figure>

				<p><formula>0.999 1.000 1.000 1.000 1.000 1.000 0.68 0.134 0.376 0.625 0.788 0.891 0.946 0.975 0.986 0.993 0.997 0.998 0.999 1.000 1.000 1.000 1.000 1.000 1.000 0.72 0.194 0.491 0.726 0.865 0.944 0.975 0.990 0.994 0.998 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.76 0.276 0.608 0.820 0.916 0.975 0.991 0.997 0.998 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.80 0.368 0.705 0.877 0.953 0.989 0.997 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.84 0.471 0.801 0.935 0.980 0.996 0.998 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.88 0.581 0.883 0.969 0.995 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.92 0.717 0.946 0.991 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.96 0.859 0.985 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.00 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000</formula></p>

				<p>(y/µ) n=19 n=20 n=21 n=22 n=23 n=24 n=25 n=26 n=27 n=28 n=29 n=30 n=31 n=32 n=33 n=34 n=35 n=36</p>

				<figure>
					<trash>≤0.10 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.12 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.002 0.003 0.003 0.007 0.14 0.000 0.000 0.000 0.000 0.000 0.001 0.002 0.002 0.003 0.006 0.009 0.014 0.021 0.033 0.046 0.059 0.074 0.093 0.16 0.001 0.002 0.003 0.005 0.009 0.015 0.025 0.036 0.052 0.069 0.093 0.117 0.143 0.168 0.199 0.232 0.273 0.315 0.18 0.010 0.014 0.025 0.036 0.055 0.084 0.119 0.155 0.193 0.227 0.271 0.313 0.352 0.396 0.437 0.482 0.521 0.560 0.20 0.057 0.081 0.117 0.154 0.200 0.249 0.293 0.344 0.385 0.433 0.492 0.533 0.571 0.611 0.645 0.682 0.717 0.751 0.22 0.164 0.209 0.269 0.321 0.370 0.423 0.476 0.528 0.576 0.625 0.676 0.715 0.744 0.777 0.800 0.824 0.854 0.874 0.24 0.313 0.368 0.432 0.493 0.547 0.596 0.651 0.696 0.731 0.767 0.804 0.835 0.855 0.879 0.893 0.908 0.928 0.939 0.26 0.486 0.548 0.609 0.655 0.703 0.748 0.786 0.820 0.841 0.870 0.895 0.913 0.929 0.940 0.950 0.958 0.966 0.972 0.28 0.627 0.686 0.736 0.781 0.814 0.847 0.874 0.893 0.912 0.930 0.946 0.954 0.962 0.968 0.975 0.980 0.985 0.987 0.30 0.745 0.789 0.826 0.858 0.881 0.904 0.926 0.941 0.956 0.966 0.975 0.980 0.985 0.987 0.991 0.993 0.995 0.996 0.32 0.826 0.866 0.895 0.917 0.932 0.946 0.958 0.966 0.975 0.982 0.989 0.992 0.994 0.995 0.996 0.997 0.998 0.999 0.34 0.887 0.915 0.931 0.947 0.956 0.965 0.975 0.980 0.987 0.990 0.994 0.996 0.997 0.998 0.999 0.999 1.000 1.000 0.36 0.931 0.950 0.963 0.972 0.977 0.981 0.988 0.990 0.993 0.995 0.996 0.998 0.999 1.000 1.000 1.000 1.000 1.000 0.38 0.960 0.975 0.982 0.987 0.990 0.991 0.995 0.996 0.998 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.40 0.979 0.986 0.991 0.994 0.995 0.997 0.999 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 ≥0.42 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 (y/µ) n=37 n=38 n=39 n=40 n=41 n=42 n=43 n=44 n=45 n=46 n=47 n=48 n=49 n=50 n=51 n=52 n=53 n=54 ≤0.08 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.10 0.000 0.000 0.000 0.000 0.001 0.001 0.001 0.001 0.002 0.002 0.004 0.005 0.008 0.011 0.013 0.017 0.022 0.034 0.12 0.010 0.013 0.021 0.025 0.034 0.045 0.057 0.067 0.084 0.098 0.118 0.142 0.167 0.190 0.214 0.240 0.267 0.301 0.14 0.114 0.144 0.172 0.198 0.228 0.261 0.297 0.329 0.358 0.390 0.422 0.458 0.497 0.527 0.557 0.586 0.614 0.640 0.16 0.353 0.396 0.434 0.469 0.504 0.540 0.582 0.617 0.648 0.674 0.700 0.724 0.751 0.775 0.795 0.813 0.831 0.847 0.18 0.603 0.641 0.673 0.706 0.731 0.763 0.786 0.806 0.828 0.847 0.864 0.876 0.893 0.901 0.914 0.925 0.934 0.943 0.20 0.783 0.812 0.834 0.857 0.876 0.893 0.909 0.920 0.932 0.940 0.948 0.955 0.960 0.965 0.970 0.973 0.977 0.982 0.22 0.897 0.913 0.924 0.937 0.947 0.956 0.964 0.969 0.975 0.979 0.982 0.984 0.986 0.988 0.990 0.991 0.993 0.993 0.24 0.951 0.959 0.965 0.973 0.979 0.982 0.984 0.986 0.989 0.991 0.993 0.994 0.996 0.997 0.997 0.999 0.999 0.999 0.26 0.978 0.982 0.987 0.990 0.991 0.993 0.994 0.994 0.995 0.997 0.998 0.998 0.998 0.999 0.999 0.999 1.000 1.000 0.28 0.990 0.992 0.995 0.995 0.996 0.996 0.997 0.997 0.998 0.999 0.999 0.999 0.999 0.999 0.999 0.999 1.000 1.000 ≥0.30 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000</trash>

					<figDesc>TABLE II: Table of maximum patch CDF&apos;s (thê h c,k (xSI)&apos;s of section IV A) given an observation of n = 55, ..., 100 events. These values of the CDFs are given as a function of the observed maximum patch divided by the total expected number of events. Upper limits can be set on two-dimensional data with these tabulated CDFs following the recipe laid out in section IV C.</figDesc>

				</figure>

				<p>(y/µ) n=55 n=56 n=57 n=58 n=59 n=60 n=61 n=62 n=63 n=64 n=65 n=66 n=67 n=68 n=69 n=70 n=71 n=72</p>

				<figure>
					<trash>≤0.07 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.08 0.001 0.001 0.001 0.001 0.001 0.001 0.002 0.003 0.003 0.004 0.005 0.006 0.008 0.010 0.012 0.014 0.017 0.020 0.09 0.006 0.008 0.011 0.015 0.018 0.023 0.029 0.033 0.041 0.045 0.053 0.061 0.073 0.084 0.097 0.109 0.125 0.137 0.10 0.041 0.050 0.067 0.079 0.092 0.110 0.127 0.145 0.162 0.184 0.205 0.221 0.244 0.266 0.290 0.316 0.348 0.367 0.11 0.156 0.178 0.205 0.228 0.249 0.276 0.299 0.324 0.354 0.381 0.409 0.436 0.460 0.484 0.512 0.541 0.567 0.592 0.12 0.327 0.351 0.383 0.412 0.436 0.470 0.500 0.526 0.552 0.577 0.600 0.626 0.655 0.674 0.699 0.722 0.738 0.758 0.13 0.504 0.534 0.570 0.594 0.616 0.640 0.665 0.690 0.713 0.733 0.754 0.770 0.791 0.810 0.828 0.841 0.853 0.865 0.14 0.669 0.696 0.722 0.746 0.764 0.780 0.800 0.816 0.836 0.852 0.864 0.873 0.884 0.895 0.911 0.917 0.924 0.932 0.15 0.781 0.800 0.822 0.837 0.854 0.864 0.879 0.890 0.904 0.914 0.923 0.929 0.936 0.943 0.953 0.955 0.959 0.962 0.16 0.859 0.874 0.890 0.899 0.911 0.917 0.926 0.934 0.943 0.947 0.956 0.959 0.963 0.968 0.975 0.976 0.979 0.982 0.17 0.915 0.927 0.936 0.943 0.950 0.952 0.958 0.963 0.968 0.971 0.976 0.978 0.980 0.983 0.987 0.988 0.989 0.991 0.18 0.950 0.957 0.963 0.968 0.971 0.973 0.978 0.981 0.986 0.987 0.988 0.990 0.991 0.993 0.995 0.995 0.995 0.996 0.19 0.974 0.978 0.981 0.984 0.986 0.987 0.990 0.991 0.994 0.995 0.995 0.996 0.996 0.997 0.998 0.998 0.998 0.999 0.20 0.985 0.987 0.989 0.991 0.993 0.994 0.995 0.996 0.998 0.998 0.998 0.998 0.999 0.999 0.999 0.999 1.000 1.000 0.21 0.991 0.993 0.993 0.995 0.997 0.997 0.998 0.998 0.999 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.22 0.995 0.996 0.996 0.997 0.998 0.999 0.999 0.999 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.23 0.998 0.999 0.999 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 ≥0.24 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 (y/µ) n=73 n=74 n=75 n=76 n=77 n=78 n=79 n=80 n=81 n=82 n=83 n=84 n=85 n=86 n=87 n=88 n=89 n=90 ≤0.05 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.06 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.001 0.001 0.001 0.07 0.000 0.001 0.001 0.003 0.004 0.005 0.005 0.007 0.007 0.010 0.012 0.015 0.018 0.021 0.023 0.027 0.031 0.039 0.08 0.024 0.029 0.035 0.042 0.050 0.058 0.068 0.078 0.087 0.101 0.114 0.128 0.140 0.156 0.172 0.186 0.205 0.222 0.09 0.154 0.173 0.190 0.206 0.226 0.246 0.271 0.295 0.314 0.342 0.363 0.386 0.409 0.429 0.449 0.472 0.498 0.518 0.10 0.389 0.414 0.437 0.458 0.478 0.502 0.528 0.552 0.570 0.593 0.613 0.632 0.653 0.668 0.686 0.703 0.721 0.737 0.11 0.613 0.634 0.653 0.672 0.690 0.706 0.728 0.743 0.760 0.775 0.789 0.804 0.814 0.824 0.836 0.847 0.860 0.869 0.12 0.774 0.790 0.803 0.818 0.831 0.843 0.852 0.861 0.873 0.882 0.893 0.902 0.909 0.916 0.922 0.927 0.933 0.940 0.13 0.876 0.890 0.896 0.904 0.912 0.920 0.925 0.930 0.938 0.944 0.950 0.956 0.960 0.963 0.966 0.969 0.971 0.975 0.14 0.938 0.946 0.950 0.956 0.960 0.964 0.967 0.971 0.975 0.977 0.979 0.981 0.984 0.986 0.987 0.988 0.989 0.989 0.15 0.965 0.971 0.974 0.977 0.979 0.981 0.982 0.985 0.989 0.991 0.992 0.993 0.994 0.995 0.996 0.996 0.997 0.997 0.16 0.984 0.986 0.987 0.989 0.991 0.992 0.992 0.993 0.994 0.996 0.996 0.996 0.996 0.997 0.998 0.998 0.998 0.999 0.17 0.994 0.995 0.995 0.996 0.997 0.997 0.997 0.997 0.998 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.18 0.998 0.998 0.998 0.998 0.998 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 1.000 1.000 1.000 0.19 0.999 0.999 0.999 0.999 0.999 0.999 0.999 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 ≥0.20 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 (y/µ) n=91 n=92 n=93 n=94 n=95 n=96 n=97 n=98 n=99 n=100 ≤0.05 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.06 0.001 0.002 0.002 0.003 0.003 0.004 0.006 0.007 0.010 0.011 0.07 0.045 0.054 0.060 0.068 0.075 0.083 0.095 0.105 0.116 0.125 0.08 0.238 0.258 0.275 0.298 0.317 0.338 0.358 0.379 0.399 0.421 0.09 0.536 0.556 0.574 0.596 0.611 0.630 0.647 0.666 0.680 0.691 0.10 0.751 0.765 0.778 0.793 0.801 0.811 0.824 0.837 0.848 0.858 0.11 0.877 0.887 0.893 0.903 0.908 0.913 0.919 0.926 0.929 0.936 0.12 0.944 0.949 0.953 0.958 0.959 0.963 0.966 0.968 0.970 0.974 0.13 0.977 0.979 0.981 0.983 0.985 0.986 0.988 0.988 0.989 0.991 0.14 0.990 0.990 0.991 0.993 0.993 0.994 0.995 0.995 0.995 0.996 0.15 0.998 0.998 0.998 0.998 0.999 0.999 0.999 0.999 0.999 1.000 0.16 0.999 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 0.17 0.999 0.999 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 ≥0.18 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000</trash>


				</figure>

			</div>
		</body>
		<back>

			<div type="acknowledgement">
				<head>Acknowledgments</head>
				<p>This work was supported by the NSF Graduate Research Fellowship program, the MIT Pappalardo Fellowship program, and the MIT Kavli Institute. We wish to thank Steve Yellin for helpful discussions.</p>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">N</forename>
				<surname>Spergel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Astrophys. J</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page">175</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">R</forename>
				<surname>Ellis</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">K</forename>
				<forename type="middle">A</forename>
				<surname>Olive</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Santoso</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">C</forename>
				<surname>Spanos</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page">095007</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">R</forename>
				<forename type="middle">J</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Rev. Nucl. Part. Sci</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page">315</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Angle</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">XENON)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">S</forename>
				<surname>Akerib</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page">011302</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Yellin</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page">032005</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">D</forename>
				<surname>Lewin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<forename type="middle">F</forename>
				<surname>Smith</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Astropart. Phys</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">87</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Burgos</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">K</forename>
				<surname>Miuchi</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Lett</title>
		<imprint>
			<biblScope unit="volume">654</biblScope>
			<biblScope unit="issue">58</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>astro. -ph]</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Dujmic</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>physics. .ins- det]</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">N</forename>
				<surname>Spergel</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">1353</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">D</forename>
				<surname>Mei</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Hime</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page">053004</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Monroe</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">P</forename>
				<surname>Fisher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">033007</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>astro. -ph]</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">O</forename>
				<surname>Host</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">H</forename>
				<surname>Hansen</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">016</biblScope>
		</imprint>
	</monogr>
	<note>astro. -ph]</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">W</forename>
				<forename type="middle">M</forename>
				<surname>Yao</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Physics G</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">S</forename>
				<surname>Yellin</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
