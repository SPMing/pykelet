<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="file:///home/joseph/Desktop/grobid/grobid-home/schemas/rng/Grobid.rng" schematypens="http://relaxng.org/ns/structure/1.0"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Entropy of Operator-valued Random Variables: A Variational Principle for Large N Matrix Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2013-07-29">July 29, 2013</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName>
								<forename type="first">L</forename>
								<surname>Akant</surname>
							</persName>
							<affiliation>
								<orgName type="department">Department of Physics and Astronomy</orgName>
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<postCode>14627</postCode>
									<settlement>Rochester</settlement>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">G</forename>
								<forename type="middle">S</forename>
								<surname>Krishnaswami</surname>
							</persName>
							<affiliation>
								<orgName type="department">Department of Physics and Astronomy</orgName>
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<postCode>14627</postCode>
									<settlement>Rochester</settlement>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName>
								<forename type="first">S</forename>
								<forename type="middle">G</forename>
								<surname>Rajeev</surname>
							</persName>
							<affiliation>
								<orgName type="department">Department of Physics and Astronomy</orgName>
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<postCode>14627</postCode>
									<settlement>Rochester</settlement>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Entropy of Operator-valued Random Variables: A Variational Principle for Large N Matrix Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2013-07-29">July 29, 2013</date>
						</imprint>
					</monogr>
					<note>arXiv:hep-th/0111263v2 5 Dec 2001</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Large N Matrix Models</term>
					<term>Variational Principle</term>
					<term>Entropy</term>
					<term>Non-commutative 
 Probability Theory</term>
					<term>Free Algebra</term>
					<term>Cohomology * akant</term>
					<term>govind</term>
					<term>rajeev@pasrochesteredu 
 1 
 Contents</term>
				</keywords>
			</textClass>
			<abstract>
				<p>We show that, in &apos;t Hooft&apos;s large N limit, matrix models can be formulated as a classical theory whose equations of motion are the factor-ized Schwinger–Dyson equations. We discover an action principle for this classical theory. This action contains a universal term describing the en-tropy of the non-commutative probability distributions. We show that this entropy is a nontrivial 1-cocycle of the non-commutative analogue of the diffeomorphism group and derive an explicit formula for it. The action principle allows us to solve matrix models using novel variational approximation methods; in the simple cases where comparisons with other methods are possible, we get reasonable agreement.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
				<figure>
					<trash>Contents 1 Introduction 3 2 Operator-valued Random Variables 7 2.1</trash>


				</figure>

			<note>The Space of Paths . . . . . . . . . . . . . . . . . . . . . . . . . . 8 2.2 Non-commutative Probability Distributions . . . . . . . . . .</note>

				<figure>
					<trash>. . 9 3 Large N Matrix Models 11 3.1 Example</trash>


				</figure>

			<note>: the Wigner Distribution . . . . . . . . . . . . . . . . . 14 3.2 The Multivariable Wigner Distribution . . . . . . . . . . . . . .</note>

				<figure>
					<trash>. 15 4 Automorphisms of the Free algebra 15 4.1 Transformation of</trash>


				</figure>

			<note>Moments under G M . . . . . . . . . . . . . . . 16 4.2 The Lie algebra of Derivations . . . . . . . . . . . . . . . . . .</note>

				<figure>
					<trash>. 18 5 The Action Principle and Cohomology 20 6 Entropy of Non-commutative Probability Distributions 23 7 Example: Two-Matrix Models 27 7.1 Mehta&apos;s Quartic</trash>


				</figure>

			<note>Two-Matrix Model . . . . . . . . . . . . . . . . 28</note>

				<p>7.2 Two-Matrix Model with tr [A, B]</p>

			<note>2 Interaction . . . . . . . . .</note>

				<figure>
					<trash>. 30 8 Appendix: Group cohomology 31 9 Appendix: A Single Random Matrix 32 9.1</trash>


				</figure>

			<note>Explicit Variational Calculations . . . . . . . . . . . . . . . . . . 36 9.2 Non-linear Variational Change of Variables . . . . . . . . . . . . 38 9.3 Formal Power Series in One Variable . . . . . . . . . . . . . . . 39 9.4 The Group of automorphisms . . . . . . . . . . . . . . . . . . . 40 9.5 Cohomology of G . . . . . . . . . . . . . . . . . . . . . . . . . .</note>

				<figure>
					<trash>. 42 10 Appendix: Formula for Cocycle 43</trash>


				</figure>

			<div>
				<head n="1">Introduction</head>

				<p>There are many physical theories in which random variables which are operators -matrices of finite or infinite order-appear: for example, Yang-Mills theories, models for random surfaces and M-theory (an approach to a string theory of quantum gravity). In all these theories, the observables are functions of the matrices which are invariant under changes of basis; in many cases -as for Yang-Mills theories-the invariance group is quite large since it contains changes of basis that depend on position. We address the question of how to construct an effective action (probability distribution) for these gauge invariant observables induced by the original probability distribution of the matrices.</p>

				<p>Quantum Chromodynamics (QCD) is the matrix model of greatest physical interest. QCD is the widely accepted theory of strong interactions. It is a Yang- Mills theory with a non-abelian gauge group SU (N ). Thus, the microscopic degrees of freedom include a set of N × N hermitean matrices at each point of space–time: the components of the 1-form that represents the gauge field. In addition there are the quark fields that form an N -component complex vector at each point of space–time. The number of &apos;colors&apos;,N , is equal to 3 in nature.</p>

				<p>Nevertheless, will be useful to study the theory for an arbitrary value of N .</p>

				<p>Also, it will be convenient to regard U (N ) rather than SU (N ) as the gauge group.</p>

				<p>The microscopic degrees of freedom-quarks and gluons-do not describe the particles that we can directly observe[1, 2, 3]. Only certain bound states called hadrons-those that are invariant under the gauge group-are observable. This phenomenon-called confinement-is one of the deepest mysteries of theoretical physics.</p>

				<p>In earlier papers we have postulated that there is a self-contained theory of color invariant observables fully equivalent to QCD at all energies and all values of N . We have called this theory we seek &apos;Quantum HadronDynamics&apos;[4] and fully constructed it in the case of of two-dimensional space–time. Also we have shown that this theory is a good approximation to four dimensional QCD applied to Deep Inelastic Scattering: it predicts with good accuracy the parton distrbutions observed in experiments[5].</p>

				<p>Certain simplifications of the two-dimensional theory allowed us to eliminate all gluon ( matrix-valued ) degrees of freedom. This helped us to construct two dimensional Quantum Hadron Dynamics quite explicitly. To make further progress, it is necessary to understand theories in which the degrees of freedom are N × N matrices. Before studying a full-fledged matrix field theory we need to understand how to reformulate a theory of a finite number of matrices in terms of their invariants. 1 This is the problem we will solve in this paper.</p>

				<p>It is well-known that matrix models simplify enormously in the limit N → ∞ [1, 2]. The quantum fluctuations in the gauge invariant observables in gauge invariant states can be shown to be of order ¯ h N . Thus, as long as we restrict to gauge invariant observables, in the limit N → ∞ QCD must tend to some classical theory. This classical theory cannot be Yang-Mills theory, however, since the fluctuations in all states ( not just the gauge-invariant ones) would vanish in that limit. An important clue to discovering Quantum Hadron Dynamics would be to study its classical limit first. This is the strategy that worked in the case of two dimensions.</p>

				<p>The analogue of the field equations of this &apos;Classical Hadron Dynamics&apos; has been known for a long time-they are the factorized Schwinger-Dyson equations [3]. It is natural to ask if there is a variational principle from which this equation can be derived. Finding this action principle would be a major step forward in understanding hadronic physics: it would give a formulation of hadron dynamics in terms of hadronic variables, entirely independent of Yang-Mills theory. A quantization of the theory based on this action principle would recover the corrections of order 1 N . Moreover,we would be able to derive approximate solutions of the large-N field equations by the variational method.</p>

				<p>Even after the simplifications of the large N -limit, generic matrix models 1 Since we understand by now how to deal with the quark degrees of freedom in terms of invariants, it is sufficient to consider toy models for pure gauge theory, without vectorial degrees of freedom. have proved to be not exactly solvable: the factorized Schwinger–Dyson equations have proved to be generally intractable. Diagrammatic methods have been pushed to their limit[1]. To make further progress, new approximation methods are needed-based on algebraic, geometric and probabilistic ideas. Moreover, the entire theory has to be reformulated in terms of manifestly U (N )-invariant observables. Thus, the basic symmery principle that determines the theory has to be something new-the gauge group acts trivially on these observables. In previous papers[6] we had suggested that the group G of automorphisms of a free algebra-the non-commutative analogue of the diffeomorphism group-plays this crucial role in such a gauge invariant reformulation of matrix models.</p>

				<p>In this paper we finally discover this manifestly gauge invariant formulation of finite dimensional matrix models. We find that the configuration space of the theory is a coset space of G-justifying our earlier anticipation.</p>

				<p>If we restrict to observables which are invariant under the action of U (N ), we should expect that the effective action should contain some kind of entropy. The situation is analogous to that in statistical mechanics, with the gauge invariant observables playing the role of macroscopic variables. However, there are an infinite number of such observables in our case. Moreover, there is no reason to expect that the systems we are studying are in thermal equilibrium in any sense.</p>

				<p>The entropy should be the logarithm of the volume of the set of all hermitean matrices that yield a given set of values for the U (N )-invariant observables.</p>

				<p>This physical idea, motivated by Boltzmann&apos;s notions in statistical mechanics, allows us to derive an explicit formula for entropy.</p>

				<p>Our approach continues the point of view in the physics literature on random matrices [8, 10, 1, 2, 3, 11, 6, 12, 13]. It should not be surprising that our work has close relations to the theory of von-Neumann algebras-nowadays called noncommutative probability theory:after all operators are just matrices of large dimension. Voiculescu [14] has another, quite remarkable, approach to noncommutative probability distributions. Our definition in terms of moments and the group of automorphisms is closer in spirit to the physics literature. Also, the connection of entropy to the cohomology of the automorphism group is not evident in that approach. A closer connection between the mathematical and physical literature should enrich both fields.</p>

				<p>Although our primary motivation has been to study toy models of Yang-Mills theory, the matrix models we study also arise in some other physical problems.</p>

				<p>There are several recent reviews that establish these connections, so we make only some brief comments. See e.g., [15].</p>

				<p>In the language of string theory, what we seek is the action of closed string field theory. We solve this problem in a &apos;toy model&apos;-for strings on a model of space-time with a finite number of points. We find that closed string theory is a kind of Wess-Zumino-Witten model on the coset space 2 G/SG; we discover an explicit formula for the classical action, including a term which represents an anomaly-a nontrivial 1-cocycle. We hope that our work complements the other approaches to closed string field theory [16].</p>

				<p>Random matrices also appear in another approach to quantum geometry [17]. Our variational method could be useful to approximately solve these matrix models for Lorentzian geometry.</p>

				<p>Quantum chaos are often modelled by matrix models[15]. In that context the focus is often on universal properties that are independent of the particular choice of the matrix model action ( which we call S below) [23]. These universal properties are thus completely determined by the entropy. Our discovery of an explicit formula for entropy should help in deriving such universal properties for multi-matrix models: so far results have been mainly about the one-matrix model. In the current paper our focus is on the joint probability distribution, which is definitely not universal.</p>

				<p>A preliminary version of this paper was presented at the MRST 2001 conference [7]</p>

				<figure>
					<figDesc>.</figDesc>

				</figure>

			</div>
			<div>
				<head n="2">Operator-valued Random Variables</head>

				<p>Let ξ i , i = 1 · · · M be a collection of operator valued random variables. We can assume without any loss of generality that they are hermitean operators: we can always split any operator into its &apos;real&apos; and &apos;imaginary parts. If the ξ i were real-valued, we could have described their joint probability distribution as a density ( more generally a measure) on R M . When ξ i are operators that cannot be diagonalized simultaneously , this is not a meaningful notion; we must seek another definition for the notion of joint probability distribution (jpd ).</p>

				<p>The quantities of physical interest are the expectation values of functions of the basic variables ( generators) ξ i ; the jpd simply provides a rule to calculate these expectation values. We will think of these functions as polynomials in the generators( more precisely formal power series.) Thus, each random variable will be determined by a collection of tensors u = {u ∅ , u i , u i1i2 , · · ·} which are the coefficients in its expansion in terms of the generators:</p>

				<figure>
					<trash>u(ξ) = ∞ m=0 u i1···im ξ i1 · · · ξ im . (1)</trash>


				</figure>

				<p>The constant term is just a complex number: the set of indices on it is empty.</p>

				<p>If u is a polynomial, all except a finite number of the tensors will be zero. It is inconvenient to restrict to polynomials: we would not be able to find inverses of functions, for example, within the world of polynomials. The opposite extreme would be to impose no restriction at all on the tensors u: then the random variable is thought of as a formal power series. We pay a price for this: it is no longer possible to &apos;evaluate&apos; the above infinite series for any particular collection of operators ξ i : the series may not converge. Nevertheless, it makes sense to take linear combinations and to multiply such formal power series: [αu + βv] i1···im = αu i1···im + βv i1···im , [uv]</p>

				<figure>
					<trash>i1···im = m n=0 u i1···in v in+1···im . (2)</trash>


				</figure>

				<p>Note that even if there are an infinite number of non-zero elements in the tensors u or v, the sum and product is always given by finite series: there are no issues of convergence in their definition. Thus the set of formal power series form an associative 3 algebra; this is the free algebra T M on the generators ξ i .</p>

				<p>Note that the multiplication is just the direct product of tensors.</p>

				<p>As we noted above, the joint probability distribution of the ξ i is just a rule to calculate the expectation value of an arbitrary function of these generators.</p>

				<p>If we restrict to functions of ξ i that are polynomials 4 , such expectation values are determined by the moments G i1i2···in =&lt; ξ i1 ξ i2 · · · ξ in &gt; . (3)</p>

				<p>If the variables commute among each other, these moments are symmetric tensors. The most general situation that can arise in physics is that the ξ i satisfy no relations at all among each other, ( in particular they dont commute) except the associativity of multiplication. In this case the moments form tensors with no particular symmetry property. All other associative algebras can be obtained from this &apos;free algebra&apos; by imposing relations ( i.e., quotienting by some ideal of the free algebra.) Such relations can be expressed as conditions on the moments. For example, if ξ i ξ j = R kl ij ξ k ξ l , the moment tensors will satisfy conditions</p>

				<figure>
					<trash>G i1···iaia+1···im = R kl iaia+1 G i1···ia−1klia+2···im (4) involving neighboring indices. 2.1 The Space of Paths</trash>


				</figure>

				<p>Thus, in our theory, a random variable is a tensor u = (u ∅ , u i , u i1i2 , · · ·). We can regard each sequence of indices I = i 1 i 2 · · · i m as a path in the finite set 1, 2, · · · M in which the indices take their values; a tensor is then a function on this space of paths. Now,given two paths I = i 1 · · · i m and J = j 1 · · · j n , we can concatenate them: follow I after traversing J: IJ = i 1 · · · i m j 1 · · · j n . This concatenation operation is associative but not in general commutative; it has the empty path ∅ as an identity element. There is however no inverse operation, so the concatenation defines the structure of a semi-group on the space of paths.</p>

				<p>We will use upper case latin indices to denote sequences of indices or paths.</p>

				<p>Repeated indices are to be summed as usual; for example</p>

				<figure>
					<trash>u I G I = ∞ m=0 u i1···im G i1···im . (5) Also, define δ I1I2 I</trash>


				</figure>

				<p>to be one if the paths I 1 and I 2 concatenate to give the path I; and zero otherwise. ¯ I = i m i m−1 · · · i 1 denotes the reverse path. Now we can see that the direct product on tensors is just the multiplication induced by concatenation on the space of paths: [uv]</p>

				<figure>
					<trash>I = δ I I1I2 u I1 v I2 . (6)</trash>


				</figure>

				<p>A more refined notion of a path emerges if we regard the indices i as labelling the edges of a directed graph; a sequence I = i 1 i 2 i 3 · · · i n is a path only when i 1 is incident to i 2 , and i 2 incident with i 3 etc. The space of paths associated with a directed graph is still a semigroup; the associative algebra induced by concatentations is just the algebra of functions on this semi-group. Lattice gauge theory can be interpreted as a matrix model ( of unitary matrices) on a directed graph 5 that approximates space-time; for example the cubic lattice.</p>

				<p>The free algebra arises from the graph with one vertex, with every edge connecting that vertex to itself; that is why every edge is incident to every other edge. This is the case we will mostly consider in this paper. Other cases can be developed analogously.</p>

			</div>
			<div>
				<head n="2.2">Non-commutative Probability Distributions</head>

				<p>We define the &apos;non-commutative joint probability distribution&apos; of the variables ξ i to be a collection of tensors G ∅ , G i , G i1i2 , · · · satisfying the normalization 5 Directed graphs approximating space-time are called &apos;lattices&apos; in physics terminology.</p>

				<figure>
					<trash>condition 1 =&lt; 1 &gt;, (7) the hermiticity condition G * i1i2···im = G imim−1···i1 , i.e., G * I = G¯ I (8) as well as the positivity condition ∞ m,n=0 G i1i2···imj1j2···jn u im···i1 * u j1j2···jn ≥ 0, i.e.,G IJ u ¯ I * u J ≥ 0. (9) for any polynomial u(ξ) = u ∅ + u i ξ i + u i1i2</trash>


				</figure>

				<p>ξ i1 ξ i2 · · ·. Denote by P M the space of such non-commutative probability distributions. We define the expectation value of a polynomial v(ξ) = m v i1i2···im ξ i1 · · · ξ im to be</p>

				<figure>
					<trash>&lt; v(ξ) &gt;= m v i1i2···im G i1i2···im ; i.e., &lt; v(ξ) &gt;= v I G I (10)</trash>


				</figure>

				<p>If the variables ξ i are commutative with joint pdf p(x 1 , · · · x n )d</p>

				<figure>
					<trash>M x, G i1i2···in = x i1 · · · x in p(x 1 , · · · x M )d M x; (11)</trash>


				</figure>

				<p>it is clear then that the above conditions on G follow from the usual normalization , hermiticity and positivity conditions on p(x)d n x. For example, the contravariant tensors u ∅ , u i , u i1i2 define a polynomial u(ξ) = m u i1i2···im ξ i1 · · · ξ im (12) and the quantity on the lhs of the positivity condition above is just the expectation value of u † (ξ)u(ξ). In this case, the moment tensors will be real and symmetric. Upto some technical assumptions, the pdf p(x)d M x is determined uniquely by the collection of moments G i1···in . ( In the case of a single variable , the reconstruction of the pdf from the moments is the &apos;moment problem&apos; of classical analysis; it was solved at varying levels of generality by Markov, Chebycheff etc. See the excellent book by Akhiezer [18].)</p>

				<p>In the non-commutative case, the pdf no longer makes sense-even then the moments allow us to calculate expectation values of arbitrary polynomials. This motivates our definition.</p>

				<p>In the cases of interest to us in this paper, G I is cyclically symmetric. This corresponds to closed string theory or to glueball states of QCD. Open strings, or mesons would require us to study moments which are not cyclically symmetric.</p>

				<p>The theory adapts with small changes; but we wont discuss these cases here.</p>

			</div>
			<div>
				<head n="3">Large N Matrix Models</head>

				<p>The basic examples of such operator-valued random variables are random matrices of large size.</p>

				<p>A matrix model is a theory of random variables which are N × N hermitean matrices A i , i = 1, · · · M .The matrix elements of each of the A i are complexvalued random variables, with the joint probability density function on R</p>

				<figure>
					<trash>N 2 M 1 Z(S) e N tr S(A) d N 2 M A (13) where S(A) = n=1 S i1i2···in A i1 · · · A in is a polynomial called the action. Also, Z(S) is determined by the normalization condition: Z(S) = e N tr S(A) d N 2 M A. (14)</trash>


				</figure>

				<p>The expectation value of any function of the random variables is defined to be</p>

				<figure>
					<trash>&lt; f (A) &gt;= f (A) 1 Z(S) e N tr S(A) d N 2 M A (15)</trash>


				</figure>

				<p>The tensors S i1···in may be chosen to be cyclically symmetric. We assume they are such that the integrals above converge: S(A) → −∞ as |A| → ∞. The interesting observables are invariant under changes of bases. We can regard the indices i = 1, · · · M as labelling the links in some graph; then a sequence i 1 · · · i n is a path in this graph. Then Φ i1···in (A) = 1 N tr [A i1 · · · A in ] is a random variable depending on a loop in this graph. For the moment we will consider every link in the graph to be incident with every other link, so that all sequences i 1 · · · i n are allowed loops. In this case the loop variables are invariant under simultaneous changes of basis in the basic variables:</p>

				<figure>
					<trash>A i → gA i g † , g ∈ U (N ). (16)</trash>


				</figure>

				<p>If we choose some other graph, a sequence of indices is a closed loop only if the edge i 2 is adjacent to i 1 , i 3 is adjacent to i 2 and so on. The invariance group will be larger; as a result, S I is non-zero only for closed loops I.</p>

				<p>Given S, the moments of the loop variables satisfy the</p>

				<figure>
					<trash>Schwinger-Dyson equations S J1iJ2 Φ J1IJ2 + δ I1iI2 I Φ I1 Φ I2 = 0. (17) This equation can be derived by considering the infinitesimal change of vari- ables [δ v A] i = v I i A I (18) on the integral Z(S) = e N tr S(A) dA. (19)</trash>


				</figure>

				<p>The variation of a product of A&apos;s is easy to compute:</p>

				<figure>
					<trash>[δ v A] J = v I i δ J1iJ2 J A J1 A I A J2 . (20)</trash>


				</figure>

				<p>The first term in the Schwinger-Dyson equation follows from the variation of the action under this change. The second term is more subtle as it is the change of the measure of integration-the divergence of the vector field v i (A):</p>

				<figure>
					<trash>δ v (dA) = v I i ∂A a Ib ∂A a ib dA, ∂A a Ib ∂A a ib = δ I1iI2 I tr A I1 tr A I2 . (21)</trash>


				</figure>

				<p>Returning to the Schwinger-Dyson equations, we see that they are not a closed system of equations: the expectation value of the loop variables is related to that of the product of two loop variables. However, there is a remarkable simplification as N → ∞.</p>

				<p>In the planar limit N → ∞ keeping S i1···in fixed, the loop variables have no fluctuations 6 :</p>

				<figure>
					<trash>&lt; f 1 (Φ)f 2 (Φ) &gt;=&lt; f 1 (Φ) &gt;&lt; f 2 (Φ) &gt; +O( 1 N 2 ) (22) where f 1 (Φ), f 2</trash>

					<figDesc>(Φ) are polynomials of the loop variables. This means that the probability distribution of the loop variables is entirely determined by the expectation values (moments)</figDesc>
					<trash>G i1···in = lim N →∞ &lt; 1 N tr A i1 · · · A in &gt; . (23) Thus we get the factorized Schwinger–Dyson equations: S J1iJ2 G J1IJ2 + δ I1iI2 I G I1 G I2 = 0. (24)</trash>


				</figure>

				<p>Since the fluctuations in the loop variables vanishes in the planar limit, there must be some effective &apos;classical theory&apos; for these variables of which these are the equations of motion. We now seek a variational principle from which these equations follow.</p>

				<figure>
					<figDesc>Matrix models arise as toy models of Yang-Mills theory as well as string theory. The cyclically symmetric indices I = i 1 · · · i n should be interpreted as a closed curve in space-time. The observable Φ I correspong to the Wilson loop in Yang-Mills theory and to the closed string field.</figDesc>

				</figure>

				<p>To summarize, the most important examples of non-commutative probability distributions are large N matrix models:</p>

				<figure>
					<trash>G i1···in = lim N →∞ 1 N tr [A i1 · · · A in ] e N tr S J AJ dA Z(S) . (25) 6</trash>


				</figure>

				<p>This is called the planar limit, since in perturbation theory, only Feynman diagrams of planar topology contribute[1]. In the matrix model of random surface theory, one is interested in another large N limit, the double scaling limit. Here the coupling constants S I have to vary as N → ∞ and tend to certain critical values at a specified rate. The fluctuations are not small in the double scaling limit.</p>

			</div>
			<div>
				<head n="3.1">Example: the Wigner Distribution</head>

				<p>The most ubiquituous of all classical probability distributions is the Gaussian; the non-commutative analogue of this is the Wigner distribution [8] ( also called the semi-circular distribution).</p>

				<p>We begin with the simplest where we have just one generator ξ for our algebra of random variables. The algebra of random variables is then necessarily commutative and can be identified with the algebra of formal power series in one variable. The simplest example of a matrix-valued random variable is this: ξ is an N ×N hermitean matrix whose entries are mutually independent random variables of zero mean and unit variance. More precisely, the average of ξ n is,</p>

				<figure>
					<trash>&lt; ξ n &gt;= 1 N tr ξ n e − N 2 tr ξ † ξ d N 2 ξ Z N . (26)</trash>


				</figure>

				<p>The normalization constant Z N is chosen such that &lt; 1 &gt;= 1.</p>

				<p>The Wigner distribution with unit covariance is the limit as N → ∞:</p>

				<figure>
					<trash>Γ n = lim N →∞ 1 N tr ξ n e − N 2 tr ξ † ξ d N 2 ξ Z N . (27) The factorized Schwinger–Dyson equations reduce to the following recursion relations for the moments: Γ k+1 = m+n=k−1 Γ m Γ n (28) Clearly the odd moments vanish and Γ 0 = 1. Set Γ 2k = C k . Then C k+1 = m+n=k C m C n . (29)</trash>


				</figure>

				<p>The solution of the recursion relations give the moments in terms of the</p>

				<figure>
					<trash>Catalan numbers Γ 2k = C k = 1 k + 1 2k k . (30) 14 3.2 The Multivariable Wigner Distribution Let K ij be a positive matrix; i.e., such that K ij u * i u j ≥ 0 (31)</trash>


				</figure>

				<p>for all vectors u i with zero occuring only for u = 0. Then the moments of the</p>

				<p>Wigner distribution on the generators ξ i , i =</p>

				<figure>
					<trash>1, 2, · · · M are given by Γ i1···in = lim N →∞ 1 N tr [ξ i1 · · · ξ in ] e − N 2 K ij tr ξiξj d N 2 M ξ Z N (32)</trash>


				</figure>

				<p>( Again, Z N is chosen such that &lt; 1 &gt;= 1.) It is obvious that the moments of odd order vanish; also, that the second moment is</p>

				<figure>
					<trash>Γ ij = K −1 ij . (33) The higher order moments are given by the recursion relations: Γ iI = Γ ij δ I1jI2 I Γ I1 Γ I2 . (34)</trash>


				</figure>

				<p>Note that each term on the rhs corresponds to a partition of the original path I into subsequences that preserve the order. By repeated application of the recursion the rhs can be written in terms of a sum over all such &apos;non-crossing partitions&apos; into pairs. The Catalan number C k is simply the number of such non-crossing partitions into pairs of a sequence of length 2k.</p>

				<p>Our stategy for studying more general probability distributions will be to transform them to the Wigner distribution by a nonlinear change of variables.</p>

				<p>Hence the group of such transformations is of importance to us. In the next section we will study this group.</p>

			</div>
			<div>
				<head n="4">Automorphisms of the Free algebra</head>

				<p>The free algebra generated by ξ i remains unchanged ( is isomorphic) if we change to a new set of generators,</p>

				<p><formula>φ(ξ) i = ∞ m=0 φ i1···im i ξ i1 · · · ξ im (35)</formula></p>

				<p>provided that this transformation is invertible . We will often abbreviate ξ I = ξ i1 · · · ξ im so that the above equation would be φ(ξ) i = φ I i ξ I . The composition of two transformations ψ and φ can be seen to be, [(ψ • φ)]</p>

				<figure>
					<trash>K i = n≤|K| δ K P1···Pn ψ j1···jn i φ P1 j1 · · · φ Pn jn . (36)</trash>


				</figure>

				<p>Note that the composition involves only finite series even when each of the series φ and ψ is infinite.</p>

				<p>The inverse, (φ −1 ) i (ξ) ≡ χ i (ξ), is determined by the conditions [(χ • φ) i ] K = δ</p>

				<figure>
					<trash>K P1···Pn χ j1···jn i φ P1 j1 · · · φ Pn jn = δ K i . (37) They can be solved recursively for χ i J : χ i j = (φ −1 ) i j χ i j1j2 = −χ k1 j1 χ k2 j2 χ i l1 φ l1 k1k2 · · · χ i j1···jn = − m&lt;n δ P1···Pm k1···kn χ k1 j1 · · · χ kn jn χ i l1···lm φ l1 P1 · · · φ lm Pm . (38) Thus an automorphism φ has an inverse as a formal power series if and only if the linear term φ i j ξ j has an inverse; i.e, if the determinant of the matrix φ i j is non-zero. The set of such automorphisms form a group G M = Aut T M . This group plays a crucial role in our theory. 4.1 Transformation of Moments under G M Given an automorphism and a probability distribution with moments G I [φ(ξ)] i = φ I i ξ I (39) the expectation value of [φ(ξ)] i1 · · · [φ(ξ)] in : [φ * G] I = ∞ n=1 φ J1 i1 · · · φ Jn in G J1···Jn (40) We might regard these as the moments of some new probability distribution. There is a technical problem however: the sums may not converge, the group G M of formal power series includes many transformations that may not map positive tensors to positive tensors: they may not preserve the &apos;measure class&apos; of the joint probability distribution G I .</trash>


				</figure>

				<p>Given some fixed jpd ( say the Wigner distribution with unit covariance), there is a subgroup G M that maps it to probability distributions; this is the open subset of G M defined by the inequalities 7 :</p>

				<figure>
					<trash>˜ G M = φ ∈ G M | [φ * G] I1I2 u * ¯ I1 u I2 ≥ 0, . (41)</trash>

					<figDesc>for all polynomials u. Thus in the neighborhood of the identity the two groups G M and G M are the same; in particular, they have the same Lie algebra. The point is that G M and G M are Lie groups under different topologies: the series φ ∈ ˜ G M have to satisfy convergence conditions implied by the above inequalities.</figDesc>

				</figure>

				<p>It is plausible that any probability distribution can be obtained from a fixed one by some automorphism; indeed there should be many such automorphisms.</p>

				<p>As a simple example, the Wigner distribution with covariance G ij can be obtained from the one with covariance δ ij by the linear automorphism φ i j ξ j provided that G ij = k φ k i φ k j .Thus the space of Wigner distributions ( the space of positive covariance matrices) is the coset space GL M /O M .</p>

				<p>In the same spirit, we will regard the space of all probability distributions as the coset space of the group of automorphisms G M /SG M , where SG M is the subgroup of automorphisms that leave the Wigner distribution of unit covariance invariant. We can parametrize an aribitary distribution with moments G I by the transformation that relates it to the unit Wigner distribution with moments</p>

				<figure>
					<trash>Γ I : G I = ∞ n=1 φ J1 i1 · · · φ Jn in Γ J1···Jn (42)</trash>

					<figDesc>Indeed, we will see below that all moments that differ infinitesimally from a given one are obtained by such infinitesimal transformations. To rigorously 7 ¯ I denotes the reverse of the sequence: I = i 1 i 2 · · · in, ¯ I = ini n−1 · · · i 1 justify our point of view, we must prove that ( in an appropriate topology) the Lie group G is the exponential of this Lie algebra. We will not address this somewhat technical issue in this paper. In the next section we describe the Lie algebra in some more detail.</figDesc>

				</figure>

			</div>
			<div>
				<head n="4.2">The Lie algebra of Derivations</head>

				<p>An automorphism that differs only infinitesimally from the identity is a derivation of the tensor algebra. Any derivation of the free algebra is determined by its effect on the generators ξ i . They can be written as linear combinations v</p>

				<figure>
					<trash>I i L i I , where the basis elements L i I are defined by L i I ξ j = δ i j ξ I . (43) The derivations form a Lie algebra with commutation relations [L i I , L j J ] = δ J1iJ2 J L j J1IJ2 − δ I1jI2 I L i I1JI2 . (44) The change of the moments under such a derivations is : L i I G J = δ J1iJ2 J G J1IJ2 . (45)</trash>


				</figure>

				<p>We already encountered these infinitesimal variations in the derivation of the</p>

				<figure>
					<head>Schwinger–Dyson equation.</head>

					<figDesc>Let us consider the infinitisemal neighborhood of some reference distribution Γ I –for example the unit Wigner distribution. We will assume that Γ I satisfies the strict positivity condition, Γ IJ u</figDesc>

				</figure>

				<p>* I u J &gt; 0; i.e., that this quadratic form vanishes only when the polynomial u is identically zero. (This condition is satisfied by the unit Wigner distribution.) It is the analogue of the condition in classical probability theory that the probability distribution does not vanish in some neighborhood of the origin. Then, the Hankel matrix H I;J = G IJ is invertible on polynomials: it is an inner product.</p>

				<p>The infinitesimal change of moments under a derivation v = v</p>

				<figure>
					<trash>I i L i I is [L v Γ] k1···kn = v I k1 Γ Ik2···kn + cyclic permutations in (k 1 · · · k n ). (46)</trash>


				</figure>

				<p>Now, it is clear that the addition of an arbitrary infinitesimal cyclically symmetric tensor g I to Γ I can be achieved by some derivation: we just find some tensor w I of which g I is the cyclically symmetric part and put w kk1···kn = v J k Γ JK . Since the Hankel matrix is invertible, we can always find such a v. Thus an arbitrary infinitesimal change in Γ I can be achieved by some v I i .</p>

				<p>Indeed there will be many such derivations, differing by those that leave Γ I</p>

				<figure>
					<trash>invariant. The isotropy Lie algebra of Γ I is defined by v I k1 Γ Ik2···kn + cyclic permutations in (k 1 · · · k n ) = 0. (47) We can simplify this condition for the choice where Γ I is the Wigner distrbution . For n = 1 this is just v I k Γ I = 0; (48) for n = 2, we get, using the recursion relation for Wigner moments, v IjL k1 Γ k2j Γ I Γ L + k 1 ↔ k 2 = 0. (49) In general, using the iterations of the Wigner recursion relation Γ Ik1k2 = Γ k1j2 Γ k2j1 δ I1j1I2j2I3 I Γ I1 Γ I2 Γ I3 (50) etc., we get Γ k1jn−1 Γ k2jn−2 · · · Γ kn−1j1 v I1j1I2j2···jn−1In kn Γ I1 · · · Γ In (51) + cyclic permutations in (k 1 · · · k n ) = 0. (52) In other words, we should lower a certain number of indices on v I i using the second moment and contract away the rest;the resulting tensor should not have a cyclically symmetric part. It would be interesting to find the solutions of these conditions more explictly. We will not need this for our present work. 5 The Action Principle and Cohomology We seek an action Ω(G) such that its variation under an infinitesimal automor- phism L i I G J = δ J1iJ2 J G J1IJ2 is the factorized SD equation: L i I Ω(G) = S J1iJ2 G J1IJ2 + δ I1iI2 I G I1 G I2 . (53)</trash>


				</figure>

				<p>It is easy to identify a quantity that will give the first term:</p>

				<figure>
					<trash>L i I S J G J = S J1iJ2 G J1IJ2 . (54)</trash>


				</figure>

				<p>This term is simply the expectation value of the matrix model action.</p>

				<figure>
					<trash>So Ω(G) = S J G J + χ(G) (55) with L i I χ(G) = η i I ≡ δ I1iI2 I G I1 G I2 . (56)</trash>


				</figure>

				<p>This term arises from the change in the measure of integration over matrices; hence it is a kind of &apos;anomaly&apos;. Now, in order for such a function χ(G) to exist, the anomaly η</p>

				<figure>
					<trash>i I must satisfy an integrability condition L i I (L i J χ) − L j J (L i I χ) = [L i I , L j J ]χ; i.e., L i I η j J − L j J η i I − δ J1iJ2 J η j J1IJ2 + δ I1jI2 I η i I1JI2 = 0. (57) A straightforward but tedious calculation shows that this is indeed satisfied. We were not able to find a formal power series of moments satisfying this condition even after many attempts. Then we realized that, even in the case of a single matrix (treated in the appendix) there is no solution of the above equation! The condition above is in fact the statement that η i</trash>


				</figure>

				<p>I (G) is a one-cocycle of the Lie-algebra cohomology of G M valued in the space of formal power series in G. (See the appendix[20]</p>

				<figure>
					<figDesc>. ) Although η itself is a quadratic polynomial in the G, there is no polynomial or even formal power series of which it is a variation: it repesents a nontrivial element of the cohomology of G twisted by its representation on the space of formal power series in the moments. We need to look for χ in some larger class of functions on the space P M of probability distributions. Now, P M = G M /SG M , a coset space of the group of automorphisms. We can parametrize the moments in terms of the automorphism that will bring them to a standard one: G I = [φ * Γ] I . So, another way of thinking of functions on P M would be as functions on G M invariant under the action 8 of SG M . Thus, instead of power series in G I , we will have power series in the coefficients φ I i determining an automorphism. In order to stand in for a function on P M , such a power series would have to be invariant under the subgroup SG M .</figDesc>

				</figure>

				<p>Clearly, any power series of G I can be expressed as a power series of the φ I i : simply substitute [φ * Γ] I for G I . But there could be a power series in φ that is invariant under SG and still is not expressible as a power series in G. This subtle distinction is the origin of the cohomology we are discussing 9 . We can now guess that the quantity we seek is a function of this type on P M . A hint is also provided by the origin of the term η i I (G) in the Schwinger- Dyson equations. It arises from the change of the measure of integration over matrices under an infinitesimal, but nonlinear, change of variables. Thus, it should be useful to study this change of measure under a finite nonlinear change of variables-an automorphism.</p>

				<figure>
					<figDesc>More precisley, let φ(A) be a nonlinear transformation A i → φ(A) i = ∞ n=1 φ I i A I , on the space of hermitean N × N matrices. Also, let σ(φ, A) =</figDesc>

				</figure>

			</div>
			<div>
				<head>1</head>

				<figure>
					<figDesc>N 2 log det J(φ, A), where J(φ, A) is the Jacobian determinant of φ. By the multiplicative property of Jacobians, we have σ(φ 1 φ 2 , A) = σ(φ 1 , φ 2 (A)) + σ(φ 2 , A). (58)</figDesc>

				</figure>

				<p>For example, σ(φ, A) = log det φ 0 if [φ(x)] i = φ j 0i ξ j is a linear transformation: the Jacobian matrix is then a constant. It is convenient to factor out this linear transformation and write</p>

				<figure>
					<trash>[φ(A)] i = φ j 0i φ(A) j , ˜ φ(A) i = A i + ∞ n=2 φ i1···in i A i1 · · · A in . (59)</trash>

					<figDesc>We will show in the appendix that σ(φ, A) can be written in terms of the traces Φ I =</figDesc>
					<trash>1 N tr A I : σ(φ, A) = log det φ 0 + ∞ n=1 (−1) n+1 n ˜ φ K1i2L1 i1 φ K2i3L2 i2 · · · ˜ φ Kni1Ln in Φ K1···Kn Φ Ln···L1 .</trash>


				</figure>

				<p>Thus, the expectation value of σ(φ, A) with respect to some distribution can be expressed in terms of its moments G I =&lt; Φ I &gt;, in the large N limit:</p>

				<figure>
					<trash>&lt; σ(φ, A) &gt; = c(φ, G) = log det φ 1 + ∞ n=1 (−1) n+1 n ˜ φ J1i2K1 i1 φ J2i3K2 i2 · · · ˜ φ Jni1Kn in G J1···Jn G Kn···K1 .</trash>


				</figure>

				<p>The above equation for σ(φ 1 φ 2 , A) then shows that the expectation value c(φ, G) satisfies the cocycle condition:</p>

				<p><formula>c(φ 1 φ 2 , G) = c(φ 1 , φ 2 * (G)) + c(φ 2 , G). (60)</formula></p>

				<p>Moreover, if we now restrict to the case of infinitesimal transformations, φ(ξ) i = ξ i + v I i ξ I , this c(φ, G) reduces to η:</p>

				<p><formula>c(φ, G) = v I i η i I (G) + O(v 2 ). (61)</formula></p>

				<figure>
					<figDesc>Let us look at it another way: let G = φ * Γ for some reference probability distribution Γ. Then the cocycle condition gives</figDesc>
					<trash>c(φ 1 , G) = c(φ 1 φ, Γ) − c(φ, Γ). (62) Choosing φ 1 to be infinitesimal gives then, η I i (G) = L I i c(φ, Γ). (63)</trash>


				</figure>

				<p>Thus, we have solved our problem!: χ(φ) = c(φ, Γ) is a function on G M whose variation is η. But is it really a function on P M ?. In other words, is χ(φ) invariant under the right action of SG?</p>

				<figure>
					<trash>If φ 2 * Γ = Γ the cocycle condition reduces to c(φφ 2 , Γ) = c(φ, Γ) + c(φ 2 , Γ). (64)</trash>


				</figure>

				<p>We need to show that the last term is zero.</p>

				<p>We will only consider the case where the reference distribution Γ is the unit wignerian. If φ 2 (ξ) i = ξ i + v I i ξ I is infinitesimal, c(φ 2 , Γ) is just v</p>

				<figure>
					<trash>I i η i I (Γ) = v JiL i</trash>

					<figDesc>Γ J Γ L . But, since v must leave the Wigner moments Γ I unchanged, it must satisfy (49). If we contract that equation by Γ k1k2 we will get v</figDesc>
					<head>JiL i</head>


				</figure>

				<figure>
					<figDesc>Γ J Γ L = 0.</figDesc>

				</figure>

				<p>Thus χ(φ) in invariant at least under an infinitesimal φ 2 ∈ SG. Within the ultrametric topology of formal power series, the group SG should be connected, so that any element can be reached by a succession of infinitesimal transformations.</p>

				<p>To summarize, we now have an action principle for matrix models,</p>

				<figure>
					<trash>Ω(φ) = ∞ n=1 S i1···in φ J1 i1 · · · φ Jn in Γ J1···Jn + log det φ i 0j + ∞ n=1 (−1) n+1 n ˜ φ K1i1L1 i2 φ K2i2L2 i3 · · · ˜ φ KninLn i1 Γ Kn···K1 Γ L1···Ln .</trash>


				</figure>

				<p>The factorized Schwinger–Dyson equations follow from requiring that this action be extremal under infinitesimal variations of φ. By choosing an ansatz for φ that depends only on a few parameters and maximizing Ω with respect to them, we can get approximate solutions to the factorized SD equations.</p>

				<figure>
					<trash>6 Entropy of Non-commutative Probability Dis- tributions</trash>

					<figDesc>Whenever we restrict the set of allowed observables of a system, some entropy is created: it measures our ignorance of the variables we are not allowed to measure. Familiar examples arise from thermodynamics, where only a finite number of macroscopic parameters are measured. In blackhole physics where only the charge, mass and angular momentum of a blackhole can be measured by external particle scattering: the interior of a blackhole is not observable to an outside observer.</figDesc>

				</figure>

				<p>There should be a similar entropy in the theory of strong interactions due to confinement: only &apos;macroscopic&apos; observables associated to hadrons are measurable by a scattering of hadrons against each other. Quarks and gluons are observable only in this indirect way. More precisely, only color invariant observables are measurable.</p>

				<p>In this paper, we have a toy model of this entropy due to confinement of gluons: we restrict to the gauge invariant functions Φ I =</p>

			</div>
			<div>
				<head>1</head>

				<figure>
					<figDesc>N tr A I , of the matrices A 1 · · · A M . It turns out that the term χ in the action principle above is just the entropy caused by this restriction. Let Q be some space of &apos;microscopic&apos; variables with a probability measure µ, and Φ : Q → ¯ Q some map to a space of &apos;macroscopic&apos; variables. We can now define the volume of any subset of ¯ Q to be the volume of its preimage in Q: this is the induced measure ¯ µ on ¯ Q.</figDesc>

				</figure>

				<p>In particular we can consider the volume of of the pre-image of a point ¯ q ∈ ¯ Q.</p>

				<p>It is a measure of our ignorance of the microscopic variables, when ¯ q is the result of measuring the macroscopic ones. Any monotonic function of this volume is just as good a measure of this ignorance. The best choice is the logarithm of this volume, since then it would be additive for statistically independent systems.</p>

				<p>Let us denote this function on Φ(Q) by</p>

				<figure>
					<trash>σ(¯ q) = log µ Φ −1 (¯ q) . (65)</trash>

					<figDesc>The average of this quantity over ¯ Q is the entropy of the induced probability</figDesc>
					<head>distribution ¯ µ.</head>


				</figure>

				<figure>
					<figDesc>Let us apply this idea to the case where the &apos;microscopic&apos; observable is a single hermitean N × N matrix A; the &apos;macroscopic&apos; observable is the spectrum, the set of eignvalues. We disregard the information in the basis in which A is presented. We do so even if this information is measurable in principle; e.g., by interference experiments in quantum mechanics. The natural measure on the space of matrices is the uniform (Lebesgue) measure dA on R</figDesc>
					<head>MN</head>


				</figure>

			</div>
			<div>
				<head n="2">.</head>

				<p>Althogh the uniform measure is not normalizable, the volume of the space of matrices with a given spectrum {a 1 , · · · a N } is finite [10]. Upto a constant ( i.e., depending only on N ), it is 1≤i&lt;j≤N (a i − a j ) 2 . Thus the entropy is 2</p>

				<figure>
					<trash>x&lt;y ρ(x)ρ(y) log |x − y|dxdy where ρ(x) = 1 N N</trash>

					<figDesc>i=1 δ(x − a i ). This expression make sense even in the limit N → ∞: we get a continuous distribution of eigenvalues ρ(x). What is the &apos;joint spectrum&apos; of a collection of M hermitean matrices A 1 · · · A M ?</figDesc>

				</figure>

				<p>Clearly they cannot be simultaneously diagonalized, so a direct definition of this concept is impossible. Now, recall that the set of eigenvalues {a 1 · · · a N } can be recovered from the elementary symmetric functions G n =</p>

				<figure>
					<trash>1 N N i=1 a n i as the solutions of the algebraic equation 1 N x N = G 1 x N −1 − G 2 x N −2 + · · · (−1) N −1 G N . (66)</trash>

					<figDesc>The moments G n for n &gt; N are not independent: they can be expressed as polynomials of the lower ones. Although the set {a 1 · · · a N } is determined by the sequence G 1 , · · · G N , there is no explicit algebraic formula: Galois theory shows that this is impossible for N &gt; 4. Galois theory also shows that any gauge invariant polynomial of A can be expressed as a polynomial of the G 1 , · · · G N .</figDesc>

				</figure>

				<p>Thus we can regard this sequence 1 N tr A,</p>

			</div>
			<div>
				<head>1</head>

				<figure>
					<figDesc>N tr A 2 · · · as the spectrum of the matrix A. The volume i&lt;j (a i − a j ) 2 of the space of matrices with a given spectrum is a symmetric polynomial of order N (N −1) 2 in the eigenvalues. Hence, in principle, it can be expressed as a polynomial in G 1 , · · · G N , athough there does not appear to be a simple universal formula 10 .</figDesc>

				</figure>

				<p>This point of view suggests a generalization to several matrices: we can define the joint spectrum of a collection of matrices to be the quantities G i1···in = 1 N tr A i1 · · · A in . Again, there are relations among these quantities when I 10 It is possible to get a formula for the volume in terms of the first 2N moments. The complication is that only the first N moments can be freely specified. The remaining moments are determined by these , and yet, there is no algebraic formula that expresses G N+1 · · · G 2N in terms of G 1 · · · G N .</p>

				<p>is longer than N ; but it is difficult to characterize these relations explicitly.</p>

				<p>Nevertheless, it is meaningful to ask for the volume (with respect to the uniform measure on R</p>

			</div>
			<div>
				<head>MN</head>

				<figure>
					<figDesc>2 ) of the set of all matrices with a given value for the sequence G i1···in . Again, we will not get any explicit formula for entropy by pursuing this point of view. So we look for yet another way to think of the joint spectrum of a collection of matrices. We can ask how the entropy of a collection of matrices with joint spectrum G I changes if we transform them by some power series: A i → φ(A) i = φ</figDesc>
					<trash>I i A I . (67)</trash>


				</figure>

				<figure>
					<figDesc>Let c(φ, G) be this change. Then, if we perform another transformation, we must have c(φφ 2 , G) = c(φ, φ 2 * G) + c(φ 2 , G); (68)</figDesc>

				</figure>

				<p>i.e., it must be a 1-cocyle. Under infinitesimal variations, it reduces to η, since it is just the infinitesimal change in the uniform measure dA.</p>

				<figure>
					<figDesc>In the last section we obtained this c(φ, G) explicitly as a formal power series in G. It can be written as the variation c(φ, G) = χ(φ * (G)) − χ(G) (69) of some function χ of the joint spectrum G. However this χ is not a formal power series in G, so we cannot get an explicit formula for it. We can write it as an explicit formal power series in φ which is invariant under the action of SG.</figDesc>

				</figure>

				<p>Thus we see the confluence of three apparently unrelated questions: an action principle for the planar limit of matrix models ( our main interest), cohomology of the automorphism of formal power series and entropy of non-commutative variables.</p>

				<p>Voiculsecu has a somewhat different approach [14] to defining the entropy of noncommuting random variables. Upto some additive constant his definition seems to agree with ours.</p>

			</div>
			<div>
				<head n="7">Example: Two-Matrix Models</head>

				<p>Let us consider a quartic multi-matrix model with action</p>

				<figure>
					<trash>S(M ) = − tr [ 1 2 K ij A ij + 1 4 g ijkl A ijkl ]. (70) Our reference action is the gaussian 11 S 0 (M ) = − tr 1 2</trash>

					<figDesc>δ ij A i A j . We are interested in estimating the greens functions and vacuum energy in the large N</figDesc>
					<trash>limit: E exact = − lim N →∞ 1 N 2 log Z Z 0 (71)</trash>


				</figure>

				<p>where Z and Z 0 are partition functions for S and S 0 . Choose the linear change of variable A i → φ i (A) = φ j i A j . The variational matrix φ j i that maximizes Ω determines the multi-variable Wigner distribution that best approximates the quartic matrix model. For a linear change of variables, Ω[φ] = tr log[</p>

				<p><formula>φ j i ] − 1 2 K ij G ij − 1 4 g ijkl G ijkl . (72) Here G ij = φ k i φ</formula></p>

				<p>k j and G ijkl = G ij G kl + G il G jk are the greens functions of S 0 (φ −1 (A)). Thus, the matrix elements of G may be regarded as the variational parameters and the condition for an extremum is</p>

				<figure>
					<trash>1 2 K pq + 1 4 [g pqkl G kl + g ijpq G ij + g pjqk G jk + g ipql G il ] = 1 2 [G −1 ] pq (73)</trash>


				</figure>

			</div>
			<div>
				<head>11</head>

				<p>In the language of non-commutative probability theory we used earlier, what we call the gaussian in this section is really the multivariate wignerian distribution. There should be no confusion, since the wignerian moments are realized by a gaussian distribution of matrices.</p>

				<p>This is a non-linear equation for the variational matrix G, reminiscent of the self consistent equation for a mean field. To test our variational approach, we specialize to a two matrix model for which some exact results are known from the work of Mehta [24]</p>

				<figure>
					<figDesc>.</figDesc>
					<trash>7.1 Mehta&apos;s Quartic Two-Matrix Model Consider the action S(A, B) = − tr [ 1 2 (A 2 + B 2 − cAB − cBA) + g 4 (A 4 + B 4 )]. (74) which corresponds to the choices K ij = 1 −c −c 1 , g 1111 = g 2222 = g and g ijkl = 0 otherwise. 12 We restrict to |c| &lt; 1, where K ij is a positive matrix. Since S(A, B) = S(B, A) and G AB = G * BA we may take G ij = α β β α (75)</trash>


				</figure>

				<p>with α, β real. For g &gt; 0, Ω is bounded above if G ij is positive. Its maximum occurs at (α, β) determined by β =</p>

				<figure>
					<trash>cα 1+2gα and 4g 2 α 3 + 4gα 2 + (1 − c 2 − 2g)α − 1 = 0. (76)</trash>


				</figure>

				<p>We must pick the real root α(g, c) that lies in the physical region α ≥ 0. Thus, the gaussian ansatz determines the vacuum energy (</p>

				<figure>
					<trash>E(g, c) = − 1 2 log (α 2 − β 2 )) and all the greens functions (e.g. G AA = α, G AB = β, G A 4 = 2α 2 e.t.c) approximately.</trash>


				</figure>

				<p>By contrast, only a few observables of this model have been calculated exactly . Mehta [24] 13 obtains the exact vacuum energy E ex (g, c) implicitly, as 12 Kazakov relates this model to the Ising model on the collection of all planar lattices with coordination number four [25]. 13 Some other special classes of greens functions are also accessible (see [26, 12]). the solution of a quintic equation. G ex AB and G ex A 4 may be obtained by differentiation . As an illustration, we compare with Mehta&apos;s results in the weak and strong coupling regions:</p>

				<figure>
					<trash>E ex (g, 1 2 ) = −.144 + 1.78g − 8.74g 2 + · · · G ex AB (g, 1 2 ) = 2 3 − 4.74g + 53.33g 2 + · · · G ex AAAA (g, 1 2 ) = 32 9 − 34.96g + · · · E var (g, 1 2 ) = −.144 + 3.56g − 23.7g 2 + · · · G var AB (g, 1 2 ) = 2 3 − 4.74g + 48.46g 2 + · · · G var AAAA (g, 1 2 ) = 32 9 − 31.61g + 368.02g 2 + · · · e.t.c. E ex (g, c) = 1 2 log g + 1 2 log 3 − 3 4 + · · · G ex AB (g, c) → 0 as g → ∞ G ex A 4 (g, c) = 1 g + · · · . E var (g, c) = 1 2 log g + 1 2 log 2 + 1 √ 8g + O( 1 g ) G var AB (g, c) = c 2g − c (2g) 3 2 + O( 1 g 2 ) G var A 4 (g, c) = 1 g − 2 (2g) 3 2 + O( 1 g 2 ), e.t.c. (77)</trash>


				</figure>

				<p>We see that the gaussian variational ansatz provides a reasonable first approximation in both the weak and strong coupling regions. The gaussian variational ansatz is not good near singularities of the free energy (phase transitions).</p>

				<p>As |c| → 1 − , the energy E ex diverges; this is not captured well by the gaussian ansatz. This reinforces our view that the gaussian variational ansatz is the analgoue of mean field theory.</p>

				<p>The power of our variational methods is their generality. We present an approximate solution to a two matrix model, for which we could find no exact results in the literature. The action we consider is:</p>

				<figure>
					<trash>S(A, B) = − tr [ m 2 2 (A 2 + B 2 ) + c 2 (AB + BA) − g 4 [A, B] 2 ]. (78)</trash>


				</figure>

				<p>This is a caricature of the Yang-Mills action. A super-symmetric version of this model is also of interest (see [27]). Consider the regime where K</p>

				<figure>
					<trash>ij = m 2 c c m 2 is positive, k = (m 4 − c 2 ) ≥ 0. As before, we pick a gaussian ansatz and maximize Ω. We get β = − c m 2 α and G AA = G BB = α = m 2 2g [ 1 + 4g k − 1], E = − 1 2 log [ 2g + k − k 2 + 4kg 2g 2 ]. (79)</trash>


				</figure>

				<p>All other mean field greens functions can be expressed in terms of α.</p>

				<p>It is possible to improve on this gaussian variational ansatz by using nonlinear transformations. It is much easier to find first a gaussian approximation and then expand around it in a sort of loop expansion. This is the analogue of the usual Goldstone methods of many body theory. We have performed such calculations for these multimatrix models, but we will not report on them in this paper for the sake of brevity. The results are qualitatively the same. In the next section ( an appendix) we will give the departures from the gaussian ansatz in the case of the single-matrix models.</p>

			</div>
			<div>
				<head n="8">Appendix: Group cohomology</head>

				<p>Given a group G and a G-module V (i.e., a representation of G on a vector space V ), we can define a cohomology theory[20]. The r-cochains are functions</p>

				<figure>
					<trash>f : G r → V. (80) The coboundary is df (g 1 , g 2 , · · · g r+1 ) = g 1 f (g 2 , · · · g r+1 ) + r s=1 (−1) s f (g 1 , g 2 , · · · g s−1 , g s g s+1 , g s+2 , · · · g r+1 ) +(−1) r+1 f (g 1 , · · · , g r ). (81)</trash>


				</figure>

				<p>It is straightforward to check that d 2 f = 0 for all f . A chain c is a cocycle or is closed if df = 0; a cocycle is exact or is a coboundary if b = df for some f ; The rth cohomology of G twisted by the module V , H r (G, V ) is the space of closed chains modulo exact chains. H 0 (G, V ) is the space of invariant elements in V ; i.e., the space of v satisfying gv − v = 0 for all g ∈ G. A 1-cocycle is a function</p>

				<figure>
					<trash>c : G → V satisfying c(g 1 g 2 ) = g 1 c(g 2 ) + c(g 1 ). (82)</trash>


				</figure>

				<p>Solutions to this equation modulo 1-coboundaries (which are of the form b(g) = (g − 1)v for some v ∈ V ) is the first cohomology H 1 (G, V ). If G acts trivially on V , a cocycle is just a homomorphism of G to the additive group of V :</p>

				<figure>
					<trash>c(g 1 g 2 ) = c(g 2 ) + c(g 1 ). A 1-cocycle gives a way of turning a representation on V into an affine action: (g, v) → gv + c(g). (83)</trash>


				</figure>

				<p>If c(g) is a coboundary (i.e., b(g) = (g − 1)u for some u), this affine action is really a linear representation in disguise: if the origin is shifted by u we can reduce it to a linear representation. Thus the elements of H 1 (G, V ) describe G ′ , the space of smooth functions from the circle to G</p>

				<figure>
					<trash>′ : G = S 1 G ′ = {g : S 1 → G ′ }. Let V = S 1</trash>

					<figDesc>G ′ be the corresponding loop of the Lie algebra G ′ of G ′ .</figDesc>

				</figure>

				<p>Then there is an obvious adjoint representation of G on V ; a non-trivial 1-cocycle is c(g) = gdg −1 , d being the exterior derivative on the circle:</p>

				<figure>
					<trash>c(g 1 g 2 ) = g 1 [g 2 d(g −1 2 )]g −1 1 + g 1 dg −1 1 = ad g 1 c(g 2 ) + c(g 1 ). (84)</trash>


				</figure>

			</div>
			<div>
				<head n="9">Appendix: A Single Random Matrix</head>

				<p>In the special case where there is only one matrix (M = 1), there is a probability distribution on the real line ρ(x)dx such that</p>

				<figure>
					<trash>G n = x n ρ(x)dx (85) This follows because the G n satisfy the positivity condition ∞ m,n=0 G n+m u * m u n ≥ 0; (86)</trash>


				</figure>

				<p>upto technical conditions, any sequence of real numbers satisfying this condition determine a probability distribution on the real line. ( This is the classical moment problem solved in the nineteenth century [18].) There is an advantage to transforming the factorized SD equations into an equation for ρ(x)-it becomes a linear integral equation, the Mehta-Dyson equation[10]</p>

				<figure>
					<trash>: 2P b a ρ(y)dy x − y + S ′ (x) = 0. (87)</trash>


				</figure>

				<p>Moreover, the solution[22, 23] to this equation can be expressed in purely</p>

				<figure>
					<trash>algebraic terms 14 ρ(x) = − 1 2π θ(a ≤ x ≤ b) √ [(x − a)(b − x)] S ′ (x) √ (x − a)(x − b) . (88) 14 For a Laurent series X(z) = m k=−∞ X k z k around infinity, ⌊X(z)⌋ = m k=0</trash>


				</figure>

				<p>X k z k denotes the part that is a polynomial in z. This is analogous to the &apos;integer part&apos; of a real number, which explains the notation.</p>

				<p>The numbers a and b are solutions of the algebraic equations r,s=0 [r +</p>

				<figure>
					<trash>s + 1]S r+s+1 ( 1 2 ) r ( 1 2 ) s r!s! a r b s = 0 r,s=0 [r + s]S r+s ( 1 2 ) r ( 1 2 ) s r!s! a r b s = 2 (89) where ( 1 2 ) r = 1 2 ( 1 2 + 1) · · · ( 1 2</trash>


				</figure>

				<p>+ r − 1). The simplest example is the case of the Wigner distribution. It is the analogue of the Gaussian in the world of noncommutative probability distributions. For, if we choose the matrix elements of</p>

				<figure>
					<trash>A to be independendent Gaussians, S(A) = − 1 2 tr A 2</trash>

					<figDesc>, we get the distribution function for the eigenvalues of A to be ( in the large N limit)</figDesc>
					<trash>ρ 0 (x) = 1 2π √ 4 − x 2 θ(|x| &lt; 2). (90)</trash>


				</figure>

				<p>The odd moments vanish; the even moments are then given by the</p>

				<figure>
					<trash>Catalan numbers G 2k = C k = 1 k + 1 2k k . (91) The Mehta-Dyson equation follows from maximizing the &apos;action&apos; Ω(ρ) = ρ(x)S(x)dx + P log |x − y|ρ(x)ρ(y)dxdy (92)</trash>


				</figure>

				<p>with respect to ρ(x). Then generating function log Z(S) is the maximum of this functional over all probability distributions ρ. The physical meaning of the first term is clear: it is just the expectation value of the action of the original matrix model: ρ(x)S(x)dx = n G n S n . (93)</p>

				<p>The second term can be thought of as the &apos;entropy&apos; which arises because we have lost the information about the angular variables in the matrix variable: the function ρ(x) is the density of the distribution of the eigenvalues of A. Indeed, i =j log |a i −a j | is (upto a constant depending only on N ) the log of the volume of the space of all hermitean matrices with spectrum a 1 , a 2 · · · a N .The entropy P log |x − y|ρ(x)ρ(y)dxdy is the large N limit of this quantity. Note that the entropy is independent of the choice of the matrix model action: it is a universal property of all one-matrix models. The meaning of the variational principle is now clear: we seek the probability distribution of maximum entropy that has a given set of moments G r for r = 1, · · · n. The coefficients of the polynomial S are just the Lagrange multipliers that enforce this condition. Thus we found a variational principle, but indirectly in terms of the function ρ(x) rather than the moments G n themselves. The entropy could not be expressed explicitly in terms of the moments. Indeed, in a sense, this is impossible: The entropy cannot be expressed as a formal power series in G n . This is surprising since there appears to be a linear relation between ρ(x) and G n , since G n = x n ρ(x)dx; also the entropy is a quadratic function of ρ(x). So one might think that entropy is a quadratic function of the G n as well. But if we try to compute this function we will get a divergent answer. Indeed, we claim that even if we dont require the series to converge, the entropy cannot be expressed as a power series in G n .</p>

				<p>By thinking in terms of the change of variables that bring the probability distribution we seek to a standard one, we can find an explicit formula for entropy. Since we are interested in polynomial actions S(A), which are modifications of the quadratic action 1 2 A 2 , the right choice of this reference distribution is the Wigner distribution ρ 0 (x) = 1 2π √ [4 − x 2 ]θ(|x| &lt; 2). (94)</p>

				<p>There should thus be a change of variable φ(x) such that</p>

				<figure>
					<trash>G k = x k ρ(x)dx = φ(x) k ρ 0 (x)dx; (95) in other words, ρ(φ(x))φ ′ (x) = ρ 0 (x). (96) Then we get Ω(φ) = S(φ(x))ρ 0 (x)dx + log φ(x) − φ(y) x − y ρ 0 (x)dxρ 0 (y)dy. (97)</trash>


				</figure>

				<p>We have dropped a constant term-the entropy of the reference distribution itself. Also it will be convenient to choose the constant of integration such that φ(0) = 0. Now we can regard the diffeomorphism as parametrized by its</p>

				<p><formula>Taylor coefficients φ(x) = ∞ n=1 φ n x n , φ 1 &gt; 0. (98)</formula></p>

				<p>Although we cannot express the entropy in terms of the moments G n themselves , we will be able to express both the entropy and the moments in terms of the parameters φ n . Thus we have a &apos;parametric form&apos; of the variational problem . It is this parametric form that we can extend to the case of multi-matrix</p>

				<figure>
					<trash>models. Indeed, φ k (x) = ∞ n=1 x n l1+l2+···l k =n φ l1 · · · φ l k (99) so that G k = ∞ n=1 Γ n l1+l2+···l k =n φ l1 · · · φ l k . (100)</trash>


				</figure>

				<p>It is convenient to factor out the linear transformation φ(x) = φ 1 [x +</p>

				<figure>
					<trash>˜ φ(x)],where φ(x) = ∞ k=2 φ k x k , with φ k = φ k [φ 1 ] −1 .Then log φ(x) − φ(y) x − y = log φ 1 + log 1 + ∞ m=2 φ m x m − y m x − y . (101) Using x m − y m x − y = k+1+l=m; k,l≥0 x k y l (102) and expanding the logarithm we get log φ(x) − φ(y) x − y = log φ 1 + ∞ n=1 (−1) n+1 n k1,l1,···kn, lñ φ k1+1+l1 · · · ˜ φ kn+1+ln x k1+···kn y l1+···ln (103) It follows then that Ω(φ) = ∞ k,n=1 S k Γ n l1+l2+···l k =n φ l1 · · · φ l k + log φ 1 + ∞ n=1 (−1) n+1 n k1,l1,···kn, lñ φ k1+1+l1 · · · ˜ φ kn+1+ln Γ k1+···kn Γ l1+···ln (104)</trash>


				</figure>

				<p>While this formula may not be particularly transparent, it does accomplish our goal of finding a variational principle that determines the moments. The parameters φ k characterize the probability distribution of the eigenvalues: they determine the moments G n by the above series. By extremizing the action Ω as a function of these φ k , we can then determine the moments. We will be able to generalize this version of the action principle to multi-matrix models. In practice we would choose some simple function φ(x) such as a polynomial to get an approximate solution to this variational problem. Since all one-matrix models are exactly solvable, we can use them to test the accuracy of our variational approximation.</p>

			</div>
			<div>
				<head n="9.1">Explicit Variational Calculations</head>

				<p>Consider the quartic one matrix model. Its exact solution in the large N limit is known from the work of Brezin et. al. [22]</p>

				<figure>
					<figDesc>:</figDesc>
					<trash>Z(g) = dAe N tr [− 1 2 A 2 −gA 4 ] E exact (g) = − lim N →∞ 1 N 2 log Z(g) Z(0) (105)</trash>


				</figure>

				<p>The gaussian with unit covariance is our reference action. Choose as a variational ansatz the linear change of variable φ(x) = φ 1 x, which merely scales the Wigner distribution. The φ 1 that maximizes Ω represents the Wigner distribution that best approximates the quartic matrix model.</p>

				<figure>
					<trash>Ω(φ 1 ) = log φ 1 − 1 2 G 2 − gG 4 (106) Here G 2k = φ 2k 1 Γ k . Letting α = φ 2 1 , Ω(α) = 1 2 log α − α 2 − 2gα 2 is bounded above only for g ≥ 0. It&apos;s maximum occurs at α(g) = −1+ √ 1+32g 16g</trash>


				</figure>

			</div>
			<div>
				<head>. Notice that</head>

				<p>α is determined by a non-linear equation. This is reminiscent of mean field theory; we will sometimes refer to the gaussian ansatz as mean field theory.</p>

				<p>Our variational estimates are:</p>

				<figure>
					<trash>E(g) = − 1 2 log −1 + √ 1 + 32g 16g G 2k (g) = ( −1 + √ 1 + 32g 16g ) k C k . (107)</trash>


				</figure>

				<p>The exact results from [22] are:</p>

				<figure>
					<trash>E ex (g) = 1 24 (a 2 (g) − 1)(9 − a 2 (g)) − 1 2 log (a 2 (g)) G 2k ex (g) = (2k)! k!(k + 2)! a 2k (g)[2k + 2 − ka 2 (g)]. (108) where a 2 (g) = 1 24g [−1 + √ 1 + 48g]</trash>


				</figure>

				<p>. In both cases, the vacuum energy is analytic at g = 0 with a square root branch point at a negative critical coupling. The mean field critical coupling g</p>

				<figure>
					<trash>MF c = − 1 32 is 50% more than the exact value g ex c = − 1 48 .</trash>


				</figure>

				<p>The distribution of eigenvalues of the best gaussian approximation is given by ρ g (x) = φ</p>

				<figure>
					<trash>−1 1 ρ 0 (φ −1 1 x) where ρ 0 (x) = 1 2π √ 4 − x 2 , |x| ≤ 2 is the standard Wigner distribution. The exact distribution ρ ex (x, g) = 1 π ( 1 2 + 4ga 2 (g) + 2gx 2 ) 4a 2 (g) − x 2 , |x| ≤ 2a(g). (109)</trash>


				</figure>

				<p>is compared with the best gaussian approximation in figure 1. The latter does not capture the bimodal property of the former.</p>

				<p>The vacuum energy estimate starts out for small g, being twice as big as the exact value. But the estimate improves and becomes exact as g → ∞.</p>

				<p>Meanwhile, the estimate for G 2 (g) is within 10% of its exact value for all g. G 2k , k ≥ 2 for the gaussian ansatz do not have any new information. However, the higher cumulants vanish for this ansatz.</p>

				<p>We see that a gaussian ansatz is a reasonable first approximation, and is not restricted to small values of the coupling g. To improve on this, get a nontrivial estimate for the higher cumulants and capture the bimodal distribution of eigenvalues, we need to make a non-linear change of variable.</p>

			</div>
			<div>
				<head n="9.2">Non-linear Variational Change of Variables</head>

				<p>The simplest non-linear ansatz for the quartic model is a cubic polynomial: φ(x) = φ 1 x + φ 3 x 3 . A quadratic ansatz will not lower the energy since S(A) is even. Our reference distribution is still the standard Wigner distribution. φ 1,3 are determined by the condition that Ω[φ] =&lt; log |</p>

				<figure>
					<trash>φ(x) − φ(y) x − y | &gt; 0 − 1 2 &lt; φ 2 (x) &gt; −g &lt; φ 4 (x) &gt; 0 (110) be a maximum.</trash>


				</figure>

				<p>Considering the success of the linear change of variable, we expect the deviations of φ 1,3 from their mean field values ( √ α, 0) to be small, irrespective of g. Within this approximation, we get (with α =</p>

				<figure>
					<trash>−1+ √ 1+32g 16g ) φ 1 = √ α − √ α(−3 + 2α + (1 − 32g)α 2 + 48gα 3 + 144g 2 α 4 ) 3 + 4α + (1 + 96g)α 2 + 48gα 3 + 432g 2 α 4 φ 3 = 8gα 5 2 (−2 + α) 3 + 4α + (1 + 96g)α 2 + 48gα 3 + 432g 2 α 4 . (111)</trash>


				</figure>

				<p>from which we calculate the variational greens functions and vacuum energy.</p>

				<p>The procedure we have used to obtain φ 1,3 can be thought of as a 1 loop calculation around mean field theory.</p>

				<p>Comparing with the exact results of [22], we find the following qualitative improvements over the mean field ansatz.</p>

				<p>In addition to the mean field branch cut from −∞ to g MF c , the vacuum energy now has a double pole at g</p>

				<p><formula>MF c &lt; g 1−loop c = −346−25 √ 22 15138 &lt; g ex c . We can -1 -0.5 0.5 1 x 0.1 0.2 0.3 0.4 0.5 0.6</formula></p>

				<p>Eigenvalue Distribution Figure 1: Eigenvalue Distribution. Dark curve is exact, semicircle is mean field and bi-modal light curve is cubic ansatz at 1-loop. understand this double pole as a sort of Padé approximation to a branch cut that runs all the way up to g ex c . The vacuum energy variational estimate is lowered for all g. Figure 1 demonstrates that the cubic ansatz is able to capture the bimodal nature of the exact eigenvalue distribution. If χ(x) = φ −1 (x), then ρ(x) = ρ 0 (χ(x))χ ′ (x), where ρ 0 (x) =</p>

			</div>
			<div>
				<head n="1">2π</head>

				<p>√ 4 − x 2 , |x| ≤ 2.</p>

				<p>The greens functions G 2 , G 4 are now within a percent of their exact values, for all g. More significantly, the connected 4-point function G</p>

				<figure>
					<trash>c 4 = G 4 − 2(G 2 ) 2</trash>


				</figure>

				<p>which vanished for the gaussian ansatz, is non-trivial, and within 10% of its exact value, across all values of g.</p>

			</div>
			<div>
				<head n="9.3">Formal Power Series in One Variable</head>

				<p>Given a sequence of complex numbers (a 0 , a 1 , a 2 , · · ·), with only a finite number of non-zero entries, we have a polynomial with these numbers as coefficients[28]</p>

				<figure>
					<figDesc>:</figDesc>

				</figure>

				<p><formula>a(z) = ∞ n=0 a n z n . (112)</formula></p>

				<p>Note that all the information in a polynomial is in its coefficients: the variable z is just a book-keeping device. In fact we could have defined a polynomial as a sequence of complex numbers (a 0 , a 1 , · · ·) with a finite number of nonzero elements. The addition multiplication and division of polynomials can be expressed directly in terms of these coefficients: [a + b] n = a n + b n , [ab] n = k + l = n a k b l , [Da]</p>

				<figure>
					<figDesc>n = (n + 1)a n+1 . (113)</figDesc>

				</figure>

				<p>A formal power series (a 0 , a 1 , · · ·) is a sequence of complex numbers, with possibly an infinite number of non-zero terms. We define the sum, product and derivative as for polynomials above: [a + b] n = a n + b n , [ab] n = k + l = n a k b l , [Da] n = (n + 1)a n+1 . (114)</p>

				<p>The set of formal power series is a ring, indeed even an integral domain. ( The proof is the same as above for polynomials.) The opration D is a derivation on this ring. The ring of formal power series is often denoted by C[[z]]. The idea is that such a sequence can be thought of as the coefficients of a series ∞ n=0 a n z n ; the sum and product postulated are what you would get from this interpretation. However, the series may not make converge if z is thought of as a complex number: hence the name formal power series.</p>

				<p>The composition a • b is well-defined whenever b 0 = 0: [a • b] n =</p>

				<figure>
					<trash>∞ k=0 a k l1+···l k =n b l1 b l2 · · · b l k . (115)</trash>


				</figure>

				<p>The point is that, for each n there are only a finite number of such l&apos;s so that the series on the rhs is really a finite series. In terms of series, this means we substitute one series into the other:</p>

				<figure>
					<trash>a • b(z) = a(b(z)). (116) 9.4 The Group of automorphisms The set of formal power series G = {φ(z) = ∞ 0 φ n z n |φ 0 = 0; φ 1 = 0} (117)</trash>


				</figure>

				<p>is a group under composition: the group of automorphisms. The group law is [ ˜ φ • φ]</p>

				<figure>
					<trash>n = n k=1 φ k l1+l2···+l k =n φ l1 · · · φ l k (118) The inverse of φ (say φ) is determined by the recursion relations of Lagrange: ˜ φ 1 φ 1 = 1, ˜ φ n = − 1 φ n 1 n−1 k=1 φ k l1+···l k =n φ l1 · · · φ l k . (119)</trash>


				</figure>

				<p>G is a topological group with respect to the ultrametric topology. It can be thought of as a Lie group, the coefficients φ n being the co-ordinates. The group multiplication law can now be studied in the case where the left or the right element is infinitesimal, leading to two sets of vector fields on the group manifold. For example, if φ(x) = x + ǫx k+1 , the change it would induce on the co-ordinates of φ is [L k φ]</p>

				<figure>
					<trash>n = l1+l2···l k+1 =n φ l1 · · · φ l k+1 (120) or equivalently, L k φ(x) = φ(x) k+1 , for k = 0, 1, 2 · · · . (121) By choosing φ(x) = x + ǫx k+1 in φ • φ we get the infinitesimal right action: R k φ(x) = x k+1 Dφ(x), for k = 0, 1, 2 · · · . (122)</trash>


				</figure>

				<p>Both sets satisfy the commutation relations of the Lie algebra G: [L m , L n ] = (n − m)L m+n , [R m , R n ] = (n − m)R m+n . (123)</p>

				<p>This Lie algebra is also called the Virasoro algebra by some physicists and the Witt algebra by some mathematicians.</p>

				<p>There is a representation of this Lie algebra on the space of formal power series:</p>

				<figure>
					<trash>L n a = x n+1 Da (124) 9.5 Cohomology of G</trash>

					<figDesc>Now let V be the space of formal power series with real coefficients. Then G, the group of automorphims has a representation on V :</figDesc>
					<trash>G = {φ : Z + → R|φ 0 = 0, φ 1 &gt; 0}, V = {a : Z + → R}, φ * a(x) = a(φ −1 (x)). (125) Now, log[φ(x)/x]</trash>


				</figure>

				<p>is a power series in x because φ(x)/x is a formal power series with positive constant term: [φ(x)/x] 0 = φ 1 &gt; 0. We see easily that c(φ, x) = log[φ(x)/x)] is a 1-cocycle of G twisted by the representation V :</p>

				<figure>
					<trash>c(φ 1 φ 2 , x) = log φ 1 (φ 2 (x)) x , = log φ 1 (φ 2 (x)) φ 2 (x) + log φ 2 (x) x = c(φ 1 φ 2 , φ 2 (x)) + c(φ 2 , x). (126)</trash>


				</figure>

				<p>Of course, neither log φ(x) nor log x are power series in x. So this cocycle is non-trivial.</p>

				<p>The space of formal power series in two commuting variables ( Sym 2 V ) also carries a representation of G. We again have a non-trivial 1-cocycle 15 on this representation:</p>

				<figure>
					<trash>c(φ, x, y) = log φ(x) − φ(y) x − y . (128)</trash>


				</figure>

				<p>We recognize this as the entropy of the single matrix model. The same argument shows that this is a non-trivial cocycle of G.</p>

				<p>Now we understand that the entropy of the single matrix models has the mathematical meaning of a non-trivial 1-cocycle of the group of automorphisms.</p>

				<p>It explains why we could not express the entropy as a function of the moments.</p>

				<p>This points also to a solution to the difficulty: we must think in terms of the</p>

				<figure>
					<trash>15 The formula x m − y m x − y = m−1 k=1 x k y m−k−1 (127)</trash>


				</figure>

				<p>can be used to show that c(φ, x, y) is a formal power series in x and y. automorphism φ rather than the moments as parametrizing the probability dis- tribution.</p>

			</div>
			<div>
				<head n="10">Appendix: Formula for Cocycle</head>

				<p>We will now get an explicit formula for σ( ˜ φ, A).</p>

				<figure>
					<trash>The Jacobian matrix of φ is obtained by differentiating the series φ(A) i = A i + ∞ n=2 φ i1···in i A i1 · · · A in : J a jd ib c (A) = ∂ ˜ φ a ib (A) ∂A c jd = δ j i δ a c δ d b + m+n≥1 φ i1···imjj1···jn i [A i1 · · · A im ] a c [A j1 · · · A jn ] d b := δ j i δ a c δ d b + K a jd ib c (A). (129) If we suppress the color indices a, b, c, d, J j i (A) = δ j i 1 ⊗ 1 + ˜ φ IjJ i A I ⊗ A J := δ j i 1 ⊗ 1 + K j i (A) (130) We can now compute 1 N 2 tr K n (A) = 1 N 2 K a1 i2b2 i1b1 a2 K a2 i3b3 i2b2 a2 · · · K an i1b1 inbn a1 = ˜ φ K1i2L1 i1 φ K2i3L2 i2 · · · ˜ φ Kni1Ln in 1 N [A K1 ] a1 a2 · · · [A Kn ] an a1 1 N [A L1 ] b2 b1 · · · [A Ln ] b1 bn = ˜ φ K1i2L1 i1 φ K2i3L2 i2 · · · ˜ φ Kni1Ln in Φ K1···Kn Φ Ln···L1 . Thus, σ( ˜ φ, A) = 1 N 2 log det [1 + K(A)] = ∞ n=1 (−1) n+1 n 1 N 2 tr K n = ∞ n=1 (−1) n+1 n ˜ φ K1i2L1 i1 φ K2i3L2 i2 · · · ˜ φ Kni1Ln in Φ K1···Kn Φ Ln···L1 .</trash>


				</figure>

				<p>This is the formula we presented earlier.</p>

			</div>

			<note place="foot" n="2"> G is a non-commutative analogue of the diffeomorphism group; SG is the subgroup that preserves a non-commutative analogue of volume. See below for precise definitions.</note>

			<note place="foot" n="3"> This algebra is commutative only if the number of generators M is one. 4 Not all formal power series may have finite expectation values: the series might diverge. This does not need to worry us: there is a sufficiently large family of &apos;well-behaved&apos; random variables, the polynomials.</note>

			<note place="foot" n="8"> Such an idea was used succesfully to solve a similar problem on cohomologies [21]. 9 We give a simple example in the appendix.</note>

			<note place="foot">&apos;true&apos; affine actions on V . For example let G be the loop group of a Lie group</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">G</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Under the Spell of the Gauge Principle</title>
		<meeting><address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1974" />
			<biblScope unit="page">461</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Witten</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">M</forename>
				<surname>Makeenko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<forename type="middle">A</forename>
				<surname>Migdal</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Phys</forename>
				<surname>Lett</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Erratum- ibid.B89</title>
		<imprint>
			<date type="published" when="1979" />
			<biblScope unit="page" from="437" to="269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">G</forename>
				<surname>Rajeev</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int.J.Mod.Phys</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">5583</biblScope>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Krishnaswami</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">G</forename>
				<surname>Rajeev</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Phys</forename>
				<surname>Lett</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>V</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">S</forename>
				<surname>John</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">G</forename>
				<surname>Krishnaswami</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Phys</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lett</title>
		<imprint>
			<biblScope unit="volume">487</biblScope>
			<biblScope unit="page">125</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName>
				<surname>Phys</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Lett</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theoretical High Energy Physics</title>
		<imprint>
			<publisher>MRST</publisher>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">Ed</forename>
				<forename type="middle">C R S G</forename>
				<surname>Hagen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Rajeev</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Inst. Phys. Nucl.Phys.Proc</title>
		<imprint>
			<biblScope unit="volume">9905072</biblScope>
			<biblScope unit="page" from="96" to="487" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">G</forename>
				<surname>Rajeev</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">O</forename>
				<forename type="middle">T</forename>
				<surname>Turgut</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Math. Phys</title>
		<imprint>
			<publisher>J. Math</publisher>
			<biblScope unit="volume">192</biblScope>
			<biblScope unit="issue">493</biblScope>
			<date type="published" when="1998" />
			<publisher>J. Math</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName>
				<surname>Phys</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Mod. Phys. A</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">2479</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Akant</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<forename type="middle">S</forename>
				<surname>Krishnaswami</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">G</forename>
				<surname>Rajeev</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theoretical High Energy Physics</title>
		<editor>V.Elias et. al.</editor>
		<meeting><address><addrLine>Melville</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">Proc</forename>
				<surname>Wigner</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cambridge Philos. Soc</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page">790</biblScope>
			<date type="published" when="1951" />
		</imprint>
	</monogr>
	<note>reprinted. in C. E</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Statistical Theories of Spectra: Fluctuations</title>
		<author>
			<persName>
				<surname>Porter</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1965" />
			<publisher>Academic Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">F</forename>
				<forename type="middle">J</forename>
				<surname>Dyson</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Phys</title>
		<imprint>
			<biblScope unit="volume">3157</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page">166</biblScope>
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">L</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cvitanovic, P.G. Lauwers and P.N. Scharbach, Nucl.Phys. B186</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1981" />
			<biblScope unit="page" from="49" to="165" />
		</imprint>
	</monogr>
	<note>2nd. ed. [11] P. Cvitanovic Phys</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">R</forename>
				<surname>Douglas</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Li</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Lett. B M. R. Douglas, Fields Institute Communications</title>
		<imprint>
			<biblScope unit="volume">348</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">R</forename>
				<surname>Gopakumar</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">J</forename>
				<surname>Gross</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">D</forename>
				<forename type="middle">V</forename>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucl. Phys. B</title>
		<editor>14] D. V. Voiculescu, K. J. Dykema and A. Nica Free Random Vari- ables</editor>
		<imprint>
			<publisher>American Mathematical Society</publisher>
			<biblScope unit="volume">451</biblScope>
			<biblScope unit="issue">379</biblScope>
			<date type="published" when="1992" />
			<publisher>American Mathematical Society</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName>
				<surname>Voiculescu</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Invent. Math</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">132</biblScope>
			<biblScope unit="page" from="411" to="189" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Guhr</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Mueller-Groeling</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<forename type="middle">A</forename>
				<surname>Weidenmuller</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rep</title>
		<imprint>
			<biblScope unit="volume">299</biblScope>
			<biblScope unit="page">189</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Sen</surname>
			</persName>
		</author>
		<author>
			<persName>
				<surname>Phys</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc.Suppl. 94</title>
		<meeting>.Suppl. 94</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page">35</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ambjorn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">B</forename>
				<surname>Durhuus</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">T</forename>
				<surname>Jonsson</surname>
			</persName>
		</author>
		<imprint>
			<pubPlace>Quantum Geometry, (Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">J. Ambjorn, J. Jurkiewicz, R. Loll, Phys.Rev</title>
		<imprint>
			<publisher>Univ. Press</publisher>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page">044011</biblScope>
			<date type="published" when="1997" />
			<publisher>Univ. Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">N</forename>
				<forename type="middle">I</forename>
				<surname>Akhiezer</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Classical Moment Problem</title>
		<imprint>
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Ambjorn</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<surname>Jurkiewicz</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<forename type="middle">M</forename>
				<surname>Makeenko</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Phys</forename>
				<surname>Lett</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="page">517</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The Cohomology of Groups</title>
		<author>
			<persName>
				<forename type="first">L</forename>
				<surname>Evens</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Ferretti</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">S</forename>
				<forename type="middle">G</forename>
				<surname>Rajeev</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page">2033</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Brezin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">C</forename>
				<surname>Itzykson</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">G</forename>
				<surname>Parisi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">J</forename>
				<forename type="middle">B</forename>
				<surname>Zuber</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm.Math.Phys</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName>
				<forename type="first">E</forename>
				<surname>Brezin</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Zee</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page">613</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">M</forename>
				<forename type="middle">L</forename>
				<surname>Mehta</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Math. Phys</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">327</biblScope>
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">V</forename>
				<forename type="middle">A</forename>
				<surname>Kazakov</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Lett. A</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">140</biblScope>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">M</forename>
				<surname>Staudacher</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Lett. B</title>
		<imprint>
			<biblScope unit="volume">305</biblScope>
			<biblScope unit="issue">332</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
		<author>
			<persName>
				<forename type="first">N</forename>
				<surname>Ishibashi</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Kawai</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">Y</forename>
				<surname>Kitazawa</surname>
			</persName>
		</author>
		<author>
			<persName>
				<forename type="first">A</forename>
				<surname>Tsuchiya</surname>
			</persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucl. Phys. B</title>
		<imprint>
			<biblScope unit="volume">498</biblScope>
			<biblScope unit="page">467</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Elementary Theory of Analytic Functions of One or Several Complex Variables</title>
		<author>
			<persName>
				<forename type="first">H</forename>
				<surname>Cartan</surname>
			</persName>
		</author>
		<imprint>
			<date type="published" when="1973" />
			<pubPlace>Hermann, Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
