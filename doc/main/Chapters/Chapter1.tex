% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 1. \emph{Introduction}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------

\section{Motivation}

CERN (Centre Europ\'een de la Recherche Nucl\'eaire) is the foremost European particle physics research laboratory located on the border of France and Switzerland, to the west of Geneva. The organisation, employing as many as 15,000 staff, fellows, and student, is the global leader in high energy physics research, centered around massive particle collision experiments in the Genevan subterrai. INSPIRE-HEP (inspirehep.net) is an online open access digital library for High Energy Physics (HEP) papers, deriving from the older SPIRES project (\cite{gentil2009information}), and mounted upon the Invenio digital library software package. The library comprises of over 1 million HEP articles, theses and books, each painstakingly curated by professional librarians. As in most domains, such manual work may be enhanced with the assistance of automated processes, such as software systems based on state-of-the-art computer science techniques.

Of particular interest is the annotation of scientific articles, extracting a document's metadata such that it is identifiable and may be represented as an entity of the digital library. This is what we call \emph{automatic metadata extraction} (AME). Though such technology is mainstream, at present INSPIRE-HEP has only limited solutions to this problem, relying heavily on tedious curation to complete the work. The problem of AME (Chapter \ref{Chapter3}) has been described as one of the hardest in document engineering, and a range of approaches to solving the problem exist, the most successful of which are machine learning techniques.

In this thesis, we present the state-of-the-art system for metadata extraction, GROBID, a sofware system based on machine learning approaches, and show how HEP papers have particular characteristics that require specialised extensions and feature engineering to improve the extraction accuracy.


Repeat some stuff from Chapter 4 here

\section{Aims}

In this thesis we propose a set of feature for models within the GROBID cascade (see Chapter \ref{Chapter3}). Above all, we hypothesise a qualitative difference in both the content and layout of a HEP article compared with other scientific articles, moreover implying the value of specialised model training and feature engineering. These differences are in fact directly observable in a representative HEP corpus, as we show in Chapter \ref{Chapter4}. The availability of a baseline dataset, in addition to our own custom HEP dataset allow us  . In short, our aims are therefore:

\begin{enumerate}
\item to demonstrate the existence of the HEP use case
\item to propose justifiable improvements;
\item to run experiments to confirm or reject our improvements, and;
\item to draw conclusions about what characterises good feature engineering.
\end{enumerate}

\section{Main Results}

Here we present a selection of our most significant results, the complete range of which is presented in Chapter \ref{Chapter5}.

Of the two models engineered for (see Chapters \ref{Chapter3} and \ref{Chapter4})

\section{Outline}

In this report we talk about this and that... In Chapter \ref{Chapter2} we provide a discussion of the relevant machine learning techniques, along with their algorithms, up to and including the state-of-the-art conditional random fields (CRF). Finally, in Chapter \ref{Chapter5} we summarise and assess our work, and conceive of the way our research may be continued and extended.