% Chapter 1

\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

\lhead{Chapter 1. \emph{Introduction}} % This is for the header on each page - perhaps a shortened title

%----------------------------------------------------------------------------------------

\section{Motivation}

CERN (Centre Europ\'een de la Recherche Nucl\'eaire) is the foremost European particle physics research laboratory, located on the border of France and Switzerland to the west of Geneva. The organisation, employing as many as 15,000 staff, fellows, and students at a time, is the global leader in high energy physics research, centered around massive particle collision experiments in the Franco-Swiss subterrain. INSPIRE-HEP (inspirehep.net) is an online open access digital library for high energy physics (HEP) papers built by an international collaboration of particle physics laboratories. INSPIRE-HEP derives from the older SPIRES project (\cite{gentil2009information}), and mounted upon the Invenio digital library software package. The digital library comprises of over one million HEP articles, theses and books, each painstakingly curated by professional librarians. As in most domains, such manual work may be enhanced with the assistance of automated processes, such as software systems based on state-of-the-art computer science techniques. Of particular interest is the annotation of scientific articles, that is, extracting a document's metadata from its \emph{content} such that it may be represented as an identifiable entity of the digital library. We refer to this as the problem of \emph{automatic metadata extraction} (AME). Though such technology is mainstream, at present INSPIRE-HEP has only limited solutions to this problem, relying heavily on tedious curation to complete the work. The problem of AME (Chapter \ref{Chapter3}) has been described as one of the hardest in document engineering \cite{souza2014arctic}, and a range of approaches to solving the problem exist, the most successful of which are machine learning techniques. This thesis presents a state-of-the-art open-source software for metadata extraction, GROBID, a system based on machine learning approaches, and shows how HEP papers have particular characteristics that require specialised extensions and feature engineering to improve the accuracy of extraction. Of particular note is the way a HEP paper may contain collaborations of thousands of authors (refer to Chapter \ref{Chapter4}). This alters the document layout drastically, creating structures unseen by baseline models. The requirements are therefore twofold:

\begin{enumerate}
\item to train models on a custom HEP training set, and;
\item to engineer specialised features conducive to better generalisation on HEP papers.
\end{enumerate}

\section{Aims}

Above all, we hypothesise the HEP use case: a qualitative difference in both the content and layout of a HEP article compared with other scientific articles, moreover implying the value of specialised model training and feature engineering. These differences are in fact directly observable in any representative HEP corpus, as we see in Chapter \ref{Chapter4}. The availability of a baseline dataset, in addition to our own custom HEP dataset, allow us to further experiment with hybrid datasets. This thesis proposes a set of features for models within the GROBID cascade (see Chapter \ref{Chapter3}). In short, our aims are:

\begin{enumerate}
\item to demonstrate the qualitative difference between HEP and general papers;
\item to propose improvements to model features, with suitable justifications;
\item to run experiments to confirm or reject our improvements, and;
\item to draw conclusions about what characterises good feature engineering.
\end{enumerate}

\section{Main Results}

The results of our 66 cross-validated experiments are presented in Chapter \ref{Chapter5}. These results confirm our initial hypothesis about HEP papers, as well as many of our intuitions. Concretely, we found improvements for each of the two GROBID models that we addressed, namely the \emph{header} model for processing article front matter, as well as the \emph{segmentation} model, the most important model in the cascade. In each case we found two feature variations to make substantial improvements over the baseline evaluations, making error reductions as great as $20\%-25\%$ for the most important classes.

\section{Outline}

In Chapter \ref{Chapter2} we provide a discussion of the relevant machine learning techniques, along with their solution algorithms, up to and including the state-of-the-art conditional random fields (CRF). In Chapter \ref{Chapter3} we present the problem of automatic metadata extraction, and the leading open-source software for the task, GROBID. Then, in Chapter \ref{Chapter4}, we showcase our propositions for improvements and extensions to the baseline models. In Chapter \ref{Chapter5} we present the results of our work and finally in Chapter \ref{Chapter6} we conceive of ways our research may be continued and extended.