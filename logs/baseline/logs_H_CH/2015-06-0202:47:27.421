
===== Token-level results =====


label		accuracy	precision	recall		f1

<title>		98.91		83.36		93.9		88.32
<author>		99.44		90.6		96.44		93.43
<affiliation>	99.37		93.69		91.93		92.81
<address>		99.59		92.09		92.65		92.37
<abstract>		89.79		84.27		92.68		88.28
<pubnum>		99.7		80.31		79.81		80.06
<email>		99.72		91.72		89.11		90.4
<keyword>		99.59		81.23		90.47		85.61
<copyright>		99.61		82.88		64.73		72.69
<grant>		99.79		89.91		88.3		89.1
<note>		96.56		68.53		50.99		58.47
<reference>		99.51		89.8		85		87.33
<submission>	99.72		80.04		84.03		81.99
<intro>		90.2		69.23		51.71		59.2
<date>		99.74		75.22		74.56		74.89
<web>		99.84		82.52		83.74		83.13
<date-submission>	99.95		100		24.39		39.22
<degree>		99.81		38.68		59.68		46.93
<entitle>		99.77		0		0		0
<dedication>	99.98		78.85		92.13		84.97
<phone>		99.92		61.45		39.84		48.34
<collaboration>	100		100		100		100

all fields		98.66		82.7		82.7 		82.7	(micro average)
			98.66		77.93		73.91		74.43	(macro average)

===== Field-level results =====

label		accuracy	precision	recall		f1

<title>		97.53		87.48		90.85		89.13
<author>		98.12		91.16		92.09		91.62
<affiliation>	96.98		91.71		85.81		88.66
<address>		98.05		92.48		90.28		91.37
<abstract>		98		84.79		89.85		87.25
<pubnum>		98.91		84.47		73.11		78.38
<email>		99.5		95.59		93.75		94.66
<keyword>		99.55		89.01		89.01		89.01
<copyright>		99.43		85.96		74.24		79.67
<grant>		99.75		76		79.17		77.55
<note>		94.33		62.46		59.02		60.69
<reference>		98.75		83.55		80.89		82.2
<submission>	99.07		79.82		83.49		81.61
<intro>		98.73		72.62		64.89		68.54
<date>		98.8		85.03		80.13		82.51
<web>		99.57		79.59		81.25		80.41
<date-submission>	99.89		100		44.44		61.54
<degree>		99.73		45.45		45.45		45.45
<entitle>		99.77		0		0		0
<dedication>	99.93		77.78		87.5		82.35
<phone>		99.75		50		45.45		47.62
<collaboration>	100		100		100		100

all fields		98.82		86.06		84.24 		85.14	(micro average)
			98.82		77.95		74.12		75.47	(macro average)

===== Instance-level results =====

Total expected instances: 		532
Correct instances: 		187
Instance-level recall:	35.15

===== Confusion matrix =====

<title>	5345	29	3	0	105	5	1	0	0	0	144	20	4	24	0	4	0	0	8	0	0	0
<author>	20	5205	31	15	27	0	3	0	0	0	66	2	1	13	0	6	0	2	0	0	6	0
<affiliation>	72	47	5289	179	19	0	1	4	6	6	112	4	0	0	0	3	0	11	0	0	0	0
<address>	0	32	121	3227	11	6	5	13	0	9	44	3	0	2	3	1	0	6	0	0	0	0
<abstract>	297	37	0	0	49827	19	0	25	5	0	101	36	14	3398	1	0	0	0	0	0	0	0
<pubnum>	30	2	0	3	13	775	0	0	0	0	62	15	5	7	52	7	0	0	0	0	0	0
<email>	0	1	7	12	0	0	1727	3	0	0	98	32	0	17	0	5	0	10	0	0	26	0
<keyword>	0	0	0	0	91	15	0	1567	0	0	0	0	3	56	0	0	0	0	0	0	0	0
<copyright>	0	2	0	0	172	11	6	0	668	0	170	0	0	0	3	0	0	0	0	0	0	0
<grant>	0	0	5	0	0	28	1	44	0	1087	66	0	0	0	0	0	0	0	0	0	0	0
<note>	348	381	86	35	668	41	44	214	43	107	3144	105	43	558	24	69	0	135	109	12	0	0
<reference>	22	0	5	14	19	5	0	45	53	0	209	2210	0	8	8	2	0	0	0	0	0	0
<submission>	15	5	6	2	4	0	0	0	11	0	14	11	826	0	75	11	0	3	0	0	0	0
<intro>	192	3	87	2	8027	46	0	14	0	0	231	8	0	9220	0	0	0	0	0	0	0	0
<date>	0	1	0	15	3	5	0	0	0	0	51	12	74	2	504	0	0	9	0	0	0	0
<web>	0	0	0	0	19	0	27	0	20	0	18	3	0	12	0	510	0	0	0	0	0	0
<date-submission>	0	0	0	0	0	0	0	0	0	0	0	0	62	0	0	0	20	0	0	0	0	0
<degree>	12	0	5	0	0	0	0	0	0	0	58	0	0	0	0	0	0	111	0	0	0	0
<entitle>	59	0	0	0	114	0	0	0	0	0	0	0	0	0	0	0	0	0	0	10	0	0
<dedication>	0	0	0	0	7	0	0	0	0	0	0	0	0	0	0	0	0	0	0	82	0	0
<phone>	0	0	0	0	0	9	68	0	0	0	0	0	0	0	0	0	0	0	0	0	51	0
<collaboration>	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	3


