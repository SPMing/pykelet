
===== Token-level results =====


label		accuracy	precision	recall		f1

<reference>		99.43		79.3		87.83		83.35
<note>		96.69		58.95		62.39		60.62
<web>		99.77		84.01		77.38		80.56
<title>		99.23		90.26		91.43		90.84
<author>		99.49		92.28		95.62		93.92
<affiliation>	99.46		92.37		93.1		92.73
<address>		99.61		91.38		91.67		91.52
<submission>	99.84		84.95		89.16		87
<keyword>		99.6		76.67		95.27		84.96
<abstract>		91.24		87.57		93.31		90.35
<copyright>		99.58		84.12		69.04		75.84
<pubnum>		99.72		88.19		66		75.5
<date>		99.78		78.42		75.45		76.91
<email>		99.67		92.09		82.58		87.08
<intro>		91.12		75.68		60.58		67.29
<grant>		99.81		96.17		87.66		91.72
<dedication>	99.87		35.33		56.73		43.54
<degree>		99.82		91.41		47.63		62.63
<entitle>		99.94		100		38.6		55.7
<phone>		99.91		67.63		58.39		62.67
<date-submission>	99.98		100		43.24		60.38
<collaboration>	100		0		0		0

all fields		98.8		84.76		84.76 		84.76	(micro average)
			98.74		83.18		74.43		76.91	(macro average)

===== Field-level results =====

label		accuracy	precision	recall		f1

<reference>		98.48		76.77		83.22		79.87
<note>		94.98		70.21		63.46		66.67
<web>		99.67		93.02		80		86.02
<title>		97.54		88.55		90.31		89.42
<author>		97.87		89.13		92.68		90.87
<affiliation>	96.5		87.13		86.13		86.63
<address>		98.02		90.75		90.31		90.53
<submission>	99.34		85.23		85.23		85.23
<keyword>		99.65		89.66		93.98		91.76
<abstract>		98.43		88.36		91.83		90.06
<copyright>		99.32		83.61		75		79.07
<pubnum>		99.01		90.54		67.68		77.46
<date>		98.66		86.23		77.78		81.79
<email>		99.37		95.33		88.82		91.96
<intro>		98.76		77.66		72.28		74.87
<grant>		99.75		88.46		76.67		82.14
<dedication>	99.87		83.33		55.56		66.67
<degree>		99.72		81.82		50		62.07
<entitle>		99.92		100		50		66.67
<phone>		99.77		72.73		57.14		64
<date-submission>	99.95		100		66.67		80
<collaboration>	99.97		0		0		0

all fields		98.84		86.38		84.5 		85.43	(micro average)
			98.79		86.6		75.94		80.18	(macro average)

===== Instance-level results =====

Total expected instances: 		498
Correct instances: 		205
Instance-level recall:	41.16

===== Confusion matrix =====

<reference>	1732	99	0	24	11	29	22	14	0	30	0	5	5	1	0	0	0	0	0	0	0	0
<note>	256	3116	0	265	166	89	33	54	12	216	120	31	23	14	543	51	0	3	0	0	0	2
<web>	12	70	578	0	0	0	0	0	0	42	0	0	0	23	5	0	0	0	0	17	0	0
<title>	16	224	0	4681	11	0	0	0	0	60	2	0	6	15	105	0	0	0	0	0	0	0
<author>	11	128	0	5	4780	29	3	0	35	4	0	0	0	0	4	0	0	0	0	0	0	0
<affiliation>	7	96	0	5	68	4250	105	0	6	3	0	0	0	0	12	0	0	13	0	0	0	0
<address>	16	46	0	0	24	131	2597	0	4	9	0	0	0	6	0	0	0	0	0	0	0	0
<submission>	17	16	0	5	0	0	0	666	0	0	0	0	40	3	0	0	0	0	0	0	0	0
<keyword>	0	17	0	0	0	0	0	0	1390	52	0	0	0	0	0	0	0	0	0	0	0	0
<abstract>	19	134	72	53	37	0	3	1	332	50189	0	0	0	2	2834	1	108	0	0	0	0	0
<copyright>	12	206	0	0	2	7	1	0	0	117	816	11	4	0	6	0	0	0	0	0	0	0
<pubnum>	71	82	0	17	2	0	13	0	0	1	10	530	48	0	29	0	0	0	0	0	0	0
<date>	11	49	3	2	3	0	7	28	0	12	0	10	458	0	23	0	0	1	0	0	0	0
<email>	2	174	0	0	20	1	30	0	7	6	10	7	0	1351	0	0	0	0	0	28	0	0
<intro>	2	674	35	97	0	0	11	0	14	6434	12	0	0	0	11186	0	0	0	0	0	0	0
<grant>	0	86	0	0	0	19	8	0	13	52	0	0	0	6	0	1307	0	0	0	0	0	0
<dedication>	0	13	0	0	0	0	0	0	0	32	0	0	0	0	0	0	59	0	0	0	0	0
<degree>	0	56	0	32	56	46	9	0	0	0	0	0	0	0	0	0	0	181	0	0	0	0
<entitle>	0	0	0	0	0	0	0	0	0	37	0	0	0	0	33	0	0	0	44	0	0	0
<phone>	0	0	0	0	0	0	0	0	0	14	0	7	0	46	0	0	0	0	0	94	0	0
<date-submission>	0	0	0	0	0	0	0	21	0	0	0	0	0	0	0	0	0	0	0	0	16	0
<collaboration>	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0	0


